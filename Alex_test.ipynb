{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = './dataset/processed_inputs.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_input, df_outputs):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "    ```\n",
    "    df_input = pd.read_csv('dataset/inputs.csv')\n",
    "    df_outputs = pd.read_csv('dataset/labels.csv')\n",
    "\n",
    "    df = preprocess(df_input, df_outputs)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    df = pd.merge(df_input, df_outputs, on='PatientID', how='inner')\n",
    "\n",
    "    # Which columns to keep\n",
    "    columns_to_keep = [\n",
    "        'PatientID',\n",
    "        'Sex',\n",
    "        'HIVTesting',\n",
    "        'ECigaretteUsage',\n",
    "        'DifficultyConcentrating',\n",
    "        'HadAsthma',\n",
    "        'HadDepressiveDisorder',\n",
    "        'CovidPos',\n",
    "        'FluVaxLast12',\n",
    "        'RaceEthnicityCategory',\n",
    "        'HadDiabetes',\n",
    "        'DifficultyDressingBathing',\n",
    "        'ChestScan',\n",
    "        'HadCOPD',\n",
    "        'BlindOrVisionDifficulty',\n",
    "        'HighRiskLastYear',\n",
    "        'HadAngina',\n",
    "        'PneumoVaxEver',\n",
    "        'HadSkinCancer',\n",
    "        'HadArthritis',\n",
    "        'DeafOrHardOfHearing',\n",
    "        'AlcoholDrinkers',\n",
    "        'HadKidneyDisease',\n",
    "        'TetanusLast10Tdap',\n",
    "        'SmokerStatus',\n",
    "        'HeightInMeters',\n",
    "        'BMI',\n",
    "        'HadHeartAttack'\n",
    "    ]\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # Turn to bool\n",
    "    columns_to_transform = [\n",
    "        'DifficultyConcentrating',\n",
    "        'HadAsthma',\n",
    "        'HadDepressiveDisorder',\n",
    "        'CovidPos',\n",
    "        'FluVaxLast12',\n",
    "        'DifficultyDressingBathing',\n",
    "        'ChestScan',\n",
    "        'HadCOPD',\n",
    "        'BlindOrVisionDifficulty',\n",
    "        'HighRiskLastYear',\n",
    "        'HadAngina',\n",
    "        'PneumoVaxEver',\n",
    "        'HadSkinCancer',\n",
    "        'HadArthritis',\n",
    "        'DeafOrHardOfHearing',\n",
    "        'AlcoholDrinkers',\n",
    "        'HadKidneyDisease',\n",
    "        'HadHeartAttack'\n",
    "    ]\n",
    "    df[columns_to_transform] = df[columns_to_transform].astype(bool)\n",
    "\n",
    "    # Rounding\n",
    "    df['BMI'] = df['BMI'].round(2)\n",
    "    df['HeightInMeters'] = df['HeightInMeters'].round(2)\n",
    "\n",
    "    ### Fix Column Names\n",
    "    new_columns = ['Patient ID', 'Sex', 'HIV Testing', 'E-Cigarette Usage',\n",
    "               'Difficulty Concentrating', 'Had Asthma', 'Had Depressive Disorder',\n",
    "               'Covid Positive', 'Flu Vaccine Last 12 Months', 'Race/Ethnicity Category', 'Had Diabetes',\n",
    "               'Difficulty Dressing/Bathing', 'Chest Scan', 'Had COPD',\n",
    "               'Blind or Vision Difficulty', 'High Risk Last Year', 'Had Angina',\n",
    "               'Pneumonia Vaccine Ever', 'Had Skin Cancer', 'Had Arthritis', 'Deaf or Hard of Hearing',\n",
    "               'Alcohol Drinkers', 'Had Kidney Disease', 'Tetanus Last 10 Years (Tdap)',\n",
    "               'Smoker Status', 'Height in Meters', 'BMI', 'Had Heart Attack']\n",
    "\n",
    "    df.columns = new_columns\n",
    "\n",
    "    return df\n",
    "\n",
    "df_input =  pd.read_csv('./dataset/inputs.csv')\n",
    "df_outputs = pd.read_csv('./dataset/labels.csv')\n",
    "df = preprocess(df_input, df_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_string(row):\n",
    "    # row is a row in dataframe\n",
    "    feature1 = \", \".join([f\"{col}: {row[col]}\" for col in row.keys()])\n",
    "    return feature1\n",
    "\n",
    "def format_string_ALL(df):\n",
    "    class_0 = df[df['Had Heart Attack'] == 0]\n",
    "    class_1 = df[df['Had Heart Attack'] == 1]\n",
    "\n",
    "    class_0 = class_0.sample(frac=1)\n",
    "    class_1 = class_1.sample(frac=1)\n",
    "\n",
    "    class_0 = class_0.drop(columns=[\"Patient ID\"])\n",
    "    class_1 = class_1.drop(columns=[\"Patient ID\"])\n",
    "\n",
    "    # class_0 and 1 are pandas df\n",
    "    # Generate features for class 0 and class 1\n",
    "    feature1 = [format_string(row) for _, row in class_0.sample(frac = 1).iterrows()]\n",
    "    feature2 = [format_string(row) for _, row in class_1.sample(frac = 1).iterrows()]\n",
    "\n",
    "    return feature1, feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature0, feature1 = format_string_ALL(df)\n",
    "\n",
    "train_index_0 = round(len(feature0)/10)\n",
    "train_index_1 = round(len(feature1)/10)\n",
    "test_0 = feature0[:train_index_0]\n",
    "test_1 = feature1[:train_index_1]\n",
    "train_0 = feature0[train_index_0:]\n",
    "train_1 = feature1[train_index_1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from typing import List, Tuple\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, long_list: List, short_list: List, long_label: List, short_label: List):\n",
    "        self.short_original = short_list\n",
    "        self.long_original = long_list\n",
    "        self.short_cycle = list(short_list)\n",
    "        self.long_cycle = list(long_list)\n",
    "        self.long_label = long_label\n",
    "        self.short_label = short_label\n",
    "        \n",
    "    def get_batch(self, batch_size: int) -> List[Tuple]:\n",
    "        batch = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            # Replenish and shuffle if needed\n",
    "            if not self.short_cycle:\n",
    "                self.short_cycle = list(self.short_original)\n",
    "                shuffle(self.short_cycle)\n",
    "                \n",
    "            if not self.long_cycle:\n",
    "                self.long_cycle = list(self.long_original)\n",
    "                shuffle(self.long_cycle)\n",
    "                \n",
    "            # Get next items\n",
    "            batch.append((self.long_cycle.pop(0), self.short_cycle.pop(0)))\n",
    "        \n",
    "        batch = list(zip(*batch))\n",
    "        return list(batch[0]+batch[1]), self.long_label[:batch_size] + self.short_label[:batch_size]\n",
    "\n",
    "generator = BatchGenerator(train_0, train_1, [0] * len(train_0), [1] * len(train_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import InputExample, losses\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Transformer = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = generator.get_batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model_Transformer.encode(data, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1405, -0.0765, -0.2450,  ..., -0.0922, -0.2806, -0.3450],\n",
       "        [ 0.0800, -0.0923, -0.2394,  ..., -0.0761, -0.2638, -0.3621],\n",
       "        [ 0.0796, -0.0980, -0.2346,  ..., -0.0757, -0.2676, -0.3707],\n",
       "        ...,\n",
       "        [ 0.1261, -0.0687, -0.2354,  ..., -0.0914, -0.2640, -0.3486],\n",
       "        [ 0.1135, -0.0509, -0.2353,  ..., -0.1000, -0.2823, -0.3591],\n",
       "        [ 0.1468, -0.0653, -0.2239,  ..., -0.1234, -0.2839, -0.3783]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4878],\n",
       "        [0.4917],\n",
       "        [0.4931],\n",
       "        [0.4929],\n",
       "        [0.4920],\n",
       "        [0.4863],\n",
       "        [0.4902],\n",
       "        [0.4958],\n",
       "        [0.4871],\n",
       "        [0.4940],\n",
       "        [0.4903],\n",
       "        [0.4929],\n",
       "        [0.4896],\n",
       "        [0.4925],\n",
       "        [0.4918],\n",
       "        [0.4930],\n",
       "        [0.4897],\n",
       "        [0.4908],\n",
       "        [0.4944],\n",
       "        [0.4949],\n",
       "        [0.4914],\n",
       "        [0.4910],\n",
       "        [0.4910],\n",
       "        [0.4865],\n",
       "        [0.4912],\n",
       "        [0.4868],\n",
       "        [0.4935],\n",
       "        [0.4945],\n",
       "        [0.4847],\n",
       "        [0.4844],\n",
       "        [0.4912],\n",
       "        [0.4912],\n",
       "        [0.4895],\n",
       "        [0.4880],\n",
       "        [0.4892],\n",
       "        [0.4869],\n",
       "        [0.4922],\n",
       "        [0.4910],\n",
       "        [0.4907],\n",
       "        [0.4842],\n",
       "        [0.4928],\n",
       "        [0.4908],\n",
       "        [0.4880],\n",
       "        [0.4901],\n",
       "        [0.4878],\n",
       "        [0.4910],\n",
       "        [0.4926],\n",
       "        [0.4915],\n",
       "        [0.4909],\n",
       "        [0.4846],\n",
       "        [0.4915],\n",
       "        [0.4884],\n",
       "        [0.4871],\n",
       "        [0.4892],\n",
       "        [0.4899],\n",
       "        [0.4902],\n",
       "        [0.4877],\n",
       "        [0.4898],\n",
       "        [0.4881],\n",
       "        [0.4860],\n",
       "        [0.4890],\n",
       "        [0.4899],\n",
       "        [0.4889],\n",
       "        [0.4884]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regression, self).__init__()\n",
    "        self.linear = nn.LazyLinear(1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "linear_model = Regression().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    data, label = generator.get_batch(32)\n",
    "    embedding = model_Transformer.encode(data)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Logistic Regression Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "# features, labels = batch(1000)\n",
    "# X = model_Transformer.encode(features)\n",
    "# y = np.array(labels)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.72      0.73       198\n",
      "         1.0       0.73      0.74      0.73       202\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.73      0.73      0.73       400\n",
      "weighted avg       0.73      0.73      0.73       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/xj2173/Heart-Disease-Prediction-LLM-Hackathon/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets\n",
    "# features, labels = batch(2000)\n",
    "# X_train, y_train = model_Transformer.encode(features), np.array(labels)  \n",
    "# X_test,  y_test  = model_Transformer.encode()\n",
    "# \n",
    "# \n",
    "# # Create and train the logistic regression model\n",
    "# model = LogisticRegression(penalty=None)\n",
    "# model.fit(X_train, y_train)\n",
    "# \n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# \n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
