{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10091240,"sourceType":"datasetVersion","datasetId":6222597}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TabM\n\nThis is a standalone usage example for the TabM project.\nThe easiest way to run it is [Pixi](https://pixi.sh/latest/#installation):\n\n```shell\ngit clone https://github.com/yandex-research/tabm\ncd tabm\n\n# With GPU:\npixi run -e cuda jupyter-lab example.ipynb\n\n# Without GPU:\npixi run jupyter-lab example.ipynb\n```\n\nFor the full overview of the project, and for non-Pixi environment setups, see README in the repository:\nhttps://github.com/yandex-research/tabm","metadata":{"id":"NT0drcxLB4uI"}},{"cell_type":"code","source":"!git clone https://github.com/yandex-research/tabm\n%cd tabm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8lW47AtLB6bT","outputId":"d9feea06-a076-41e4-8fd3-0685027e4d91","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:48:40.471361Z","iopub.execute_input":"2024-12-04T01:48:40.472273Z","iopub.status.idle":"2024-12-04T01:48:45.450016Z","shell.execute_reply.started":"2024-12-04T01:48:40.472215Z","shell.execute_reply":"2024-12-04T01:48:45.448888Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'tabm'...\nremote: Enumerating objects: 50606, done.\u001b[K\nremote: Counting objects: 100% (12277/12277), done.\u001b[K\nremote: Compressing objects: 100% (4503/4503), done.\u001b[K\nremote: Total 50606 (delta 7843), reused 12201 (delta 7773), pack-reused 38329 (from 1)\u001b[K\nReceiving objects: 100% (50606/50606), 12.13 MiB | 21.41 MiB/s, done.\nResolving deltas: 100% (30991/30991), done.\nUpdating files: 100% (37498/37498), done.\n/kaggle/working/tabm\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FrZDX8yB-vq","outputId":"c90f0fd4-ff93-4b77-a86e-56755195174b","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:48:45.451950Z","iopub.execute_input":"2024-12-04T01:48:45.452283Z","iopub.status.idle":"2024-12-04T01:48:56.399086Z","shell.execute_reply.started":"2024-12-04T01:48:45.452236Z","shell.execute_reply":"2024-12-04T01:48:56.397946Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# !pip install torcheval","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQjXxgHNgHdz","outputId":"3528d85e-c0f5-4dce-85a3-92312b54112b","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:48:56.400783Z","iopub.execute_input":"2024-12-04T01:48:56.401221Z","iopub.status.idle":"2024-12-04T01:48:56.405953Z","shell.execute_reply.started":"2024-12-04T01:48:56.401174Z","shell.execute_reply":"2024-12-04T01:48:56.404988Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install rtdl_num_embeddings>=0.0.11","metadata":{"id":"YbhX0tUCCJ2L","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:48:56.407950Z","iopub.execute_input":"2024-12-04T01:48:56.408351Z","iopub.status.idle":"2024-12-04T01:49:06.592938Z","shell.execute_reply.started":"2024-12-04T01:48:56.408320Z","shell.execute_reply":"2024-12-04T01:49:06.591607Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from tabm_reference import Model","metadata":{"id":"bFqaWJJiCS5t","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:06.594543Z","iopub.execute_input":"2024-12-04T01:49:06.594893Z","iopub.status.idle":"2024-12-04T01:49:10.729117Z","shell.execute_reply.started":"2024-12-04T01:49:06.594859Z","shell.execute_reply":"2024-12-04T01:49:10.728023Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ruff: noqa: E402\nimport math\nimport random\nimport warnings\nfrom typing import Literal, NamedTuple\n\nimport numpy as np\nimport rtdl_num_embeddings  # https://github.com/yandex-research/rtdl-num-embeddings\nimport scipy.special\nimport sklearn.datasets\nimport sklearn.metrics\nimport sklearn.model_selection\nimport sklearn.preprocessing\nimport torch\nimport torch.nn.functional as F\nimport torch.optim\nfrom torch import Tensor\nfrom tqdm.std import tqdm\n\nwarnings.simplefilter('ignore')\nfrom tabm_reference import Model, make_parameter_groups\n\nwarnings.resetwarnings()","metadata":{"id":"OINJLYKtB4uJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:10.740468Z","iopub.execute_input":"2024-12-04T01:49:10.740793Z","iopub.status.idle":"2024-12-04T01:49:10.846160Z","shell.execute_reply.started":"2024-12-04T01:49:10.740763Z","shell.execute_reply":"2024-12-04T01:49:10.845071Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"seed = 0\nrandom.seed(seed)\nnp.random.seed(seed + 1)\ntorch.manual_seed(seed + 2)\npass","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTdaHSj2B4uJ","outputId":"89fd0324-4562-4d9f-a493-f13f1a3717ea","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:10.847276Z","iopub.execute_input":"2024-12-04T01:49:10.847564Z","iopub.status.idle":"2024-12-04T01:49:10.857065Z","shell.execute_reply.started":"2024-12-04T01:49:10.847537Z","shell.execute_reply":"2024-12-04T01:49:10.856137Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"TMPxpg7SB4uJ"}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the uploaded data files\ninputs_path = '/kaggle/input/heart-disease-prediction-llm-hackathon/inputs.csv'\nlabels_path = '/kaggle/input/heart-disease-prediction-llm-hackathon/labels.csv'\n\ninputs_df = pd.read_csv(inputs_path)\nlabels_df = pd.read_csv(labels_path)\n\ndata = inputs_df.merge(labels_df, on=\"PatientID\")\n\n# Separate features and target\nX = data.drop(columns=[\"PatientID\", \"HadHeartAttack\"])\ny = data[\"HadHeartAttack\"]\n\n\n# Display the first few rows of the data to understand its structure\n\nbinary_columns = [\n    'Sex', 'HadAngina', 'HadStroke',\n    'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder',\n    'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty',\n    'DifficultyConcentrating', 'DifficultyWalking',\n    'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'AlcoholDrinkers',\n    'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'HighRiskLastYear', 'CovidPos'\n]\n\nfor col in binary_columns:\n    assert len(X[col].unique()) == 2\n\ncat_columns = [\n    'State', 'GeneralHealth', 'AgeCategory',\n    'HadDiabetes', 'SmokerStatus', 'ECigaretteUsage',\n    'RaceEthnicityCategory', 'TetanusLast10Tdap'\n]\n\nfor col in cat_columns:\n    print(col, len(X[col].unique()))\n\nnum_columns = ['HeightInMeters', 'WeightInKilograms', 'BMI']\n\nfor col in num_columns:\n    print(col, X[col].min(), X[col].max())\n\nX_cont = X.loc[:, num_columns].to_numpy().astype(np.float32)\nX_cat = X.loc[:, binary_columns + cat_columns]\n\nfor col in binary_columns + cat_columns:\n    X_cat[col], _ = pd.factorize(X_cat[col])\n\nX_cat = X_cat.to_numpy()\nY, _ = pd.factorize(y)\nY = Y.astype(np.int64)\n\ntask_type = \"classification\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trNbdfedDtRe","outputId":"bfaf7cbc-11a6-4b3c-8957-cb1963690bf5","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:10.860654Z","iopub.execute_input":"2024-12-04T01:49:10.861016Z","iopub.status.idle":"2024-12-04T01:49:13.100882Z","shell.execute_reply.started":"2024-12-04T01:49:10.860985Z","shell.execute_reply":"2024-12-04T01:49:13.099957Z"}},"outputs":[{"name":"stdout","text":"State 54\nGeneralHealth 5\nAgeCategory 13\nHadDiabetes 4\nSmokerStatus 4\nECigaretteUsage 4\nRaceEthnicityCategory 5\nTetanusLast10Tdap 4\nHeightInMeters 0.910000026226044 2.41000008583069\nWeightInKilograms 28.1200008392334 292.570007324219\nBMI 12.0200004577637 97.6500015258789\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"X_cat.max(axis=0)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wz31e8TeEajZ","outputId":"de950f8d-0d0b-46e0-ef8f-0ce0e0a916b2","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.102510Z","iopub.execute_input":"2024-12-04T01:49:13.102854Z","iopub.status.idle":"2024-12-04T01:49:13.113301Z","shell.execute_reply.started":"2024-12-04T01:49:13.102824Z","shell.execute_reply":"2024-12-04T01:49:13.112297Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n        1,  1,  1,  1,  1, 53,  4, 12,  3,  3,  3,  4,  3])"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"cat_cardinalities = [x + 1 for x in X_cat.max(axis=0)]\nn_cont_features = X_cont.shape[1]\nn_classes = 2","metadata":{"id":"tqBpm5NaGXbI","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.114446Z","iopub.execute_input":"2024-12-04T01:49:13.114815Z","iopub.status.idle":"2024-12-04T01:49:13.124502Z","shell.execute_reply.started":"2024-12-04T01:49:13.114783Z","shell.execute_reply":"2024-12-04T01:49:13.123623Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(f\"2's: {sum(x == 2 for x in cat_cardinalities)}\")\nprint(f\"3's: {sum(x == 4 for x in cat_cardinalities)}\")\nprint(f\"4's: {sum(x == 5 for x in cat_cardinalities)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-HvblMJGgpS","outputId":"370b7bb6-3f92-4e89-fcd2-a2f5f312751b","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.136376Z","iopub.execute_input":"2024-12-04T01:49:13.136789Z","iopub.status.idle":"2024-12-04T01:49:13.148966Z","shell.execute_reply.started":"2024-12-04T01:49:13.136745Z","shell.execute_reply":"2024-12-04T01:49:13.148043Z"}},"outputs":[{"name":"stdout","text":"2's: 22\n3's: 4\n4's: 2\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"Y.max(), Y.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlrzeJWXFl1J","outputId":"25dcf8c4-001e-47fa-8f75-74087fb23639","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.150222Z","iopub.execute_input":"2024-12-04T01:49:13.150561Z","iopub.status.idle":"2024-12-04T01:49:13.160933Z","shell.execute_reply.started":"2024-12-04T01:49:13.150531Z","shell.execute_reply":"2024-12-04T01:49:13.159667Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(1, (190157,))"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"all_idx = np.arange(len(Y))\ntrainval_idx, test_idx = sklearn.model_selection.train_test_split(\n    all_idx, train_size=0.9\n)\ntrain_idx, val_idx = sklearn.model_selection.train_test_split(\n    trainval_idx, train_size=0.9\n)\ndata_numpy = {\n    'train': {'x_cont': X_cont[train_idx], 'y': Y[train_idx]},\n    'val': {'x_cont': X_cont[val_idx], 'y': Y[val_idx]},\n    'test': {'x_cont': X_cont[test_idx], 'y': Y[test_idx]},\n}\nif X_cat is not None:\n    data_numpy['train']['x_cat'] = X_cat[train_idx]\n    data_numpy['val']['x_cat'] = X_cat[val_idx]\n    data_numpy['test']['x_cat'] = X_cat[test_idx]","metadata":{"id":"9xSKFZqhELDW","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.162605Z","iopub.execute_input":"2024-12-04T01:49:13.162943Z","iopub.status.idle":"2024-12-04T01:49:13.275941Z","shell.execute_reply.started":"2024-12-04T01:49:13.162911Z","shell.execute_reply":"2024-12-04T01:49:13.274938Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"data_numpy['train']['x_cont'].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsab0Vc4Ft3Q","outputId":"fb808567-c8bd-4cfb-a093-8a4b55af525e","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.277113Z","iopub.execute_input":"2024-12-04T01:49:13.277421Z","iopub.status.idle":"2024-12-04T01:49:13.283726Z","shell.execute_reply.started":"2024-12-04T01:49:13.277391Z","shell.execute_reply":"2024-12-04T01:49:13.282652Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(154026, 3)"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"","metadata":{"id":"jSK3I0kXD_fj"}},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{"id":"N-isFeHTB4uK"}},{"cell_type":"code","source":"# np.random.rand?","metadata":{"id":"VcpQHIA0-2aE","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.285244Z","iopub.execute_input":"2024-12-04T01:49:13.285570Z","iopub.status.idle":"2024-12-04T01:49:13.295163Z","shell.execute_reply.started":"2024-12-04T01:49:13.285541Z","shell.execute_reply":"2024-12-04T01:49:13.294147Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Feature preprocessing.\n# NOTE\n# The choice between preprocessing strategies depends on a task and a model.\n\n# Simple preprocessing strategy.\npreprocessing = sklearn.preprocessing.StandardScaler().fit(\n    data_numpy['train']['x_cont']\n)\n\nfor part in data_numpy:\n    data_numpy[part]['x_cont'] = preprocessing.transform(data_numpy[part]['x_cont'])\n\n# print(data_numpy['train']['x_cont'].mean(), data_numpy['train']['x_cont'].std())\n# Advanced preprocessing strategy.\n# The noise is added to improve the output of QuantileTransformer in some cases.\nX_cont_train_numpy = data_numpy['train']['x_cont']\nnoise = (\n    np.random.default_rng(0)\n    .normal(0.0, 1e-1, X_cont_train_numpy.shape)\n    .astype(X_cont_train_numpy.dtype)\n)\npreprocessing = sklearn.preprocessing.QuantileTransformer(\n    n_quantiles=max(min(len(train_idx) // 30, 1000), 10),\n    output_distribution='normal',\n    subsample=10**9,\n).fit(X_cont_train_numpy + noise)\ndel X_cont_train_numpy\n\n# Apply the preprocessing.\nfor part in data_numpy:\n    data_numpy[part]['x_cont'] = preprocessing.transform(data_numpy[part]['x_cont'])\n\nBINARY_AUGMENT_P = 0.\nX_cat_numpy = data_numpy['train']['x_cat']\nfor col in range(len(binary_columns)):\n    k = int(BINARY_AUGMENT_P * X_cat_numpy.shape[0])\n    indices = np.random.choice(X_cat_numpy.shape[0], size=k, replace=False)\n    X_cat_numpy[indices, col] = 1 - X_cat_numpy[indices, col]\n\nCAT_AUGMENT_P = 0.1\nfor col in range(len(binary_columns), len(binary_columns) + len(cat_columns)):\n    k = int(CAT_AUGMENT_P * X_cat_numpy.shape[0])\n    indices = np.random.choice(X_cat_numpy.shape[0], size=k, replace=False)\n    random_categories = np.random.choice(X_cat_numpy[:, col].max(axis=0) + 1, size=k)\n    X_cat_numpy[indices, col] = random_categories\n\ndata_numpy['train']['x_cat'] = X_cat_numpy\n\n\n# Label preprocessing.\nclass RegressionLabelStats(NamedTuple):\n    mean: float\n    std: float\n\n\nY_train = data_numpy['train']['y'].copy()\nif task_type == 'regression':\n    # For regression tasks, it is highly recommended to standardize the training labels.\n    regression_label_stats = RegressionLabelStats(\n        Y_train.mean().item(), Y_train.std().item()\n    )\n    Y_train = (Y_train - regression_label_stats.mean) / regression_label_stats.std\nelse:\n    regression_label_stats = None","metadata":{"id":"pVkUm1ofB4uK","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.296272Z","iopub.execute_input":"2024-12-04T01:49:13.296538Z","iopub.status.idle":"2024-12-04T01:49:13.630340Z","shell.execute_reply.started":"2024-12-04T01:49:13.296511Z","shell.execute_reply":"2024-12-04T01:49:13.629107Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"data_numpy['train']['y'].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.631680Z","iopub.execute_input":"2024-12-04T01:49:13.632050Z","iopub.status.idle":"2024-12-04T01:49:13.639233Z","shell.execute_reply.started":"2024-12-04T01:49:13.632011Z","shell.execute_reply":"2024-12-04T01:49:13.638054Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(154026,)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# # balance the train dataset\n\n# print('prev train shape:', data_numpy['train']['y'].shape[0])\n\n# class_balance = 1.5\n\n# pos_indices = np.nonzero(data_numpy['train']['y'] == 1)[0]\n# neg_indices = np.nonzero(data_numpy['train']['y'] == 0)[0]\n\n# print(pos_indices.shape[0], neg_indices.shape[0])\n\n# new_neg_indices = np.random.choice(neg_indices.shape[0], size=int(class_balance * pos_indices.shape[0]), replace=False)\n# print(new_neg_indices.shape[0])\n# for key in data_numpy['train']:\n#     new_data = np.concatenate([data_numpy['train'][key][pos_indices], data_numpy['train'][key][new_neg_indices]], axis=0)\n#     print(new_data.shape)\n#     shuffled_indices = np.random.permutation(new_data.shape[0])\n#     data_numpy['train'][key] = new_data[shuffled_indices]\n\n# print('new train shape:', data_numpy['train']['y'].shape[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.642843Z","iopub.execute_input":"2024-12-04T01:49:13.643154Z","iopub.status.idle":"2024-12-04T01:49:13.650821Z","shell.execute_reply.started":"2024-12-04T01:49:13.643125Z","shell.execute_reply":"2024-12-04T01:49:13.649911Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"#  PyTorch settings","metadata":{"id":"RfzSrmU2B4uK"}},{"cell_type":"code","source":"# Device\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Convert data to tensors\ndata = {\n    part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n    for part in data_numpy\n}\nY_train = torch.as_tensor(Y_train, device=device)\nif task_type == 'regression':\n    for part in data:\n        data[part]['y'] = data[part]['y'].float()\n    Y_train = Y_train.float()\n\n# Automatic mixed precision (AMP)\n# torch.float16 is implemented for completeness,\n# but it was not tested in the project,\n# so torch.bfloat16 is used by default.\namp_dtype = (\n    torch.bfloat16\n    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n    else torch.float16\n    if torch.cuda.is_available()\n    else None\n)\n# Changing False to True will result in faster training on compatible hardware.\namp_enabled = False and amp_dtype is not None\ngrad_scaler = torch.cuda.amp.GradScaler() if amp_dtype is torch.float16 else None  # type: ignore\n\n# torch.compile\ncompile_model = False\n\n# fmt: off\nprint(\n    f'Device:        {device.type.upper()}'\n    f'\\nAMP:           {amp_enabled} (dtype: {amp_dtype})'\n    f'\\ntorch.compile: {compile_model}'\n)\n# fmt: on","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1sqLpfyB4uK","outputId":"2d41de68-90f8-4a30-eb53-8d8d6ae647e8","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T01:49:13.651803Z","iopub.execute_input":"2024-12-04T01:49:13.652097Z","iopub.status.idle":"2024-12-04T01:49:13.917838Z","shell.execute_reply.started":"2024-12-04T01:49:13.652069Z","shell.execute_reply":"2024-12-04T01:49:13.916841Z"}},"outputs":[{"name":"stdout","text":"Device:        CUDA\nAMP:           False (dtype: torch.bfloat16)\ntorch.compile: False\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Model","metadata":{"id":"rH-ujPMWB4uL"}},{"cell_type":"code","source":"# Choose one of the two configurations below.\nfrom torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n\n# TabM\narch_type = 'tabm'\nbins = None\nk = 32\n\n# TabM-mini with the piecewise-linear embeddings.\n# arch_type = 'tabm-mini'\n# bins = rtdl_num_embeddings.compute_bins(data['train']['x_cont'])\n\nmodel = Model(\n    n_num_features=n_cont_features,\n    cat_cardinalities=cat_cardinalities,\n    n_classes=n_classes,\n    backbone={\n        'type': 'MLP',\n        'n_blocks': 3 if bins is None else 2,\n        'd_block': 512,\n        'dropout': 0.1,\n    },\n    bins=bins,\n    num_embeddings=(\n        None\n        if bins is None\n        else {\n            'type': 'PiecewiseLinearEmbeddings',\n            'd_embedding': 16,\n            'activation': False,\n            'version': 'B',\n        }\n    ),\n    arch_type=arch_type,\n    k=k,\n).to(device)\nswa_model = AveragedModel(model)\n\noptimizer = torch.optim.AdamW(make_parameter_groups(model), lr=2e-3, weight_decay=3e-4) #was 3e-4\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=1e-5)\nswa_scheduler = SWALR(optimizer, swa_lr=1.8e-3)\n\nif compile_model:\n    # NOTE\n    # `torch.compile` is intentionally called without the `mode` argument\n    # (mode=\"reduce-overhead\" caused issues during training with torch==2.0.1).\n    model = torch.compile(model)\n    evaluation_mode = torch.no_grad\nelse:\n    evaluation_mode = torch.inference_mode","metadata":{"id":"9WrYBnKUB4uL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ee7b282-9b49-48e4-8fb3-0225e9de6b78","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:29.819046Z","iopub.execute_input":"2024-12-04T02:14:29.819980Z","iopub.status.idle":"2024-12-04T02:14:29.850316Z","shell.execute_reply.started":"2024-12-04T02:14:29.819936Z","shell.execute_reply":"2024-12-04T02:14:29.849394Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"pos_weight = (len(Y_train) - Y_train.sum()) / Y_train.sum()\npos_weight","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZfjNMIWWdd3","outputId":"43fa9922-621d-44ea-9ec1-ebc10e06e57e","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:29.958278Z","iopub.execute_input":"2024-12-04T02:14:29.958677Z","iopub.status.idle":"2024-12-04T02:14:29.967439Z","shell.execute_reply.started":"2024-12-04T02:14:29.958643Z","shell.execute_reply":"2024-12-04T02:14:29.966434Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"tensor(16.9517, device='cuda:0')"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"(len(Y_train) - Y_train.sum()) / Y_train.sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3Y5ie8nBm0-","outputId":"f196d5ac-45bf-49a8-f22a-d4200d20e3ec","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:30.189086Z","iopub.execute_input":"2024-12-04T02:14:30.189468Z","iopub.status.idle":"2024-12-04T02:14:30.197929Z","shell.execute_reply.started":"2024-12-04T02:14:30.189438Z","shell.execute_reply":"2024-12-04T02:14:30.196884Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"tensor(16.9517, device='cuda:0')"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"(len(data['val']['y']) - data['val']['y'].sum()) / data['val']['y'].sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exTw4zNkBoF7","outputId":"6cd9c86b-81e6-4973-cb7e-579af250b4f7","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:30.610060Z","iopub.execute_input":"2024-12-04T02:14:30.611258Z","iopub.status.idle":"2024-12-04T02:14:30.619556Z","shell.execute_reply.started":"2024-12-04T02:14:30.611212Z","shell.execute_reply":"2024-12-04T02:14:30.618538Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"tensor(17.5831, device='cuda:0')"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"(len(data['test']['y']) - data['test']['y'].sum()) / data['test']['y'].sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaWcskLWByYq","outputId":"9c430b36-ad62-4275-f190-2bdee721a948","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:31.007944Z","iopub.execute_input":"2024-12-04T02:14:31.008377Z","iopub.status.idle":"2024-12-04T02:14:31.017364Z","shell.execute_reply.started":"2024-12-04T02:14:31.008336Z","shell.execute_reply":"2024-12-04T02:14:31.016267Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"tensor(16.7554, device='cuda:0')"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"# from torcheval.metrics.functional import binary_f1_score\n\ndef find_best_threshold(y_true, y_prob, metric=sklearn.metrics.f1_score):\n    \"\"\"\n    Find the best threshold for a binary classification task based on a given metric.\n\n    Parameters:\n    - y_true: array-like, shape (n_samples,)\n      True binary labels (0 or 1).\n    - y_prob: array-like, shape (n_samples,)\n      Predicted probabilities for the positive class.\n    - metric: callable\n      The metric to optimize. Default is F1-score.\n\n    Returns:\n    - best_threshold: float\n      The threshold that maximizes the specified metric.\n    - best_score: float\n      The best metric score.\n    \"\"\"\n    best_threshold = 0.0\n    best_score = 0.0\n\n    # Search thresholds from 0.0 to 1.0 with small steps\n    thresholds = np.linspace(0, 1, 25)\n\n    for threshold in thresholds:\n        # Convert probabilities to binary predictions\n        y_pred = (y_prob >= threshold).astype(int)\n\n        # Compute the metric\n        score = metric(y_true, y_pred)\n\n        # Update best threshold if the current score is better\n        if score > best_score:\n            best_score = score\n            best_threshold = threshold\n\n    return best_threshold, best_score","metadata":{"id":"JYtoB_0Af0wN","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:31.249497Z","iopub.execute_input":"2024-12-04T02:14:31.249944Z","iopub.status.idle":"2024-12-04T02:14:31.257123Z","shell.execute_reply.started":"2024-12-04T02:14:31.249907Z","shell.execute_reply":"2024-12-04T02:14:31.255984Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"@torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\ndef apply_model(model, part: str, idx: Tensor) -> Tensor:\n    pred = model(\n        data[part]['x_cont'][idx],\n        data[part]['x_cat'][idx] if 'x_cat' in data[part] else None,\n    )\n    # print(pred.shape, pred[..., 0].shape)\n    if task_type != \"regression\":\n        return pred.float()\n\n    return (\n        pred\n        .squeeze(-1)  # Remove the last dimension for regression tasks.\n        .float()\n    )\n\n\nif task_type == \"regression\":\n    base_loss_fn = F.mse_loss\nelif n_classes == 2:\n    base_loss_fn = F.binary_cross_entropy_with_logits # lambda x, y: F.binary_cross_entropy_with_logits(x, y, reduction='none')\nelse:\n    base_loss_fn = F.cross_entropy\n\ndef focal_loss(predictions, targets, alpha=0.25, gamma=2.0):\n    bce_loss = F.binary_cross_entropy_with_logits(predictions, targets, reduction='none', pos_weight=torch.tensor(2.))\n    pt = torch.exp(-bce_loss)  # Probability of correct class\n    loss = alpha * (1 - pt)**gamma * bce_loss\n    return loss.mean()\n\ndef loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n    # TabM produces k predictions per object. Each of them must be trained separately.\n    # (regression)     y_pred.shape == (batch_size, k)\n    # (classification) y_pred.shape == (batch_size, k, n_classes)\n    if task_type == 'regression':\n        k = y_pred.shape[-1]\n    else:\n        k = y_pred.shape[-2]\n\n    y_pred = y_pred[..., 1]\n    # print(y_pred.shape)\n\n    # return base_loss_fn(y_pred.flatten(0, 1), y_true.repeat_interleave(k))\n    # print(k, y_pred.shape, y_pred.flatten(0, 1).shape, y_true.repeat_interleave(k).shape)\n    return focal_loss(y_pred.flatten(0, 1), y_true.repeat_interleave(k)) #torch.tensor(10).to(y_pred.device)\n    # return base_loss_fn(\n    #     y_pred.flatten(0, 1), y_true.repeat_interleave(k),\n    #     pos_weight=pos_weight #torch.tensor(10).to(y_pred.device)\n    # )\n\n\n@evaluation_mode()\ndef evaluate(model, part: str) -> float:\n    model.eval()\n\n    # When using torch.compile, you may need to reduce the evaluation batch size.\n    eval_batch_size = 8096\n    y_pred: np.ndarray = (\n        torch.cat(\n            [\n                apply_model(model, part, idx)\n                for idx in torch.arange(len(data[part]['y']), device=device).split(\n                    eval_batch_size\n                )\n            ]\n        )\n        .cpu()\n        .numpy()\n    )\n    if task_type == 'regression':\n        # Transform the predictions back to the original label space.\n        assert regression_label_stats is not None\n        y_pred = y_pred * regression_label_stats.std + regression_label_stats.mean\n\n    # print(y_pred.shape)\n    # Compute the mean of the k predictions.\n    if task_type != 'regression':\n        # For classification, the mean must be computed in the probabily space.\n        y_pred = scipy.special.softmax(y_pred, axis=-1)\n    # print(y_pred.shape)\n    y_pred = y_pred.mean(1)\n    # print(y_pred.shape)\n    print('mean prediction:', (y_pred[..., -1] > 0.5).mean())\n\n    y_true = data[part]['y'].cpu().numpy()\n\n    # print(y_pred.shape)\n    # print(y_true.shape)\n\n    if task_type == 'regression':\n        score = -(sklearn.metrics.mean_squared_error(y_true, y_pred) ** 0.5)\n    else:\n        y_pred_final = y_pred[..., -1] > 0.5\n        score = sklearn.metrics.accuracy_score(y_true, y_pred_final)\n        recall = sklearn.metrics.recall_score(y_true, y_pred_final)\n        precision = sklearn.metrics.precision_score(y_true, y_pred_final)\n        print(f'({part}) recall: {recall:.4f}')\n        print(f'({part}) precision: {precision:.4f}')\n\n        best_threshold, best_score = find_best_threshold(\n            y_true, y_pred[..., -1], metric=sklearn.metrics.f1_score\n        )\n\n        print(f'({part}) BEST threshold: {best_threshold:.4f}')\n        print(f'({part}) BEST f1: {best_score:.4f}')\n\n        recall = sklearn.metrics.recall_score(y_true, (y_pred[..., -1] >= best_threshold).astype(int))\n        precision = sklearn.metrics.precision_score(y_true, (y_pred[..., -1] >= best_threshold).astype(int))\n        print(f'({part}) BEST recall: {recall:.4f}')\n        print(f'({part}) BEST precision: {precision:.4f}')\n\n    return float(score)  # The higher -- the better.\n\n\nprint(f'Test score before training: {evaluate(model, \"test\"):.4f}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"258YDtBLB4uM","outputId":"23f4223d-1dfb-482d-cd3e-55b0d1b964c5","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:31.425838Z","iopub.execute_input":"2024-12-04T02:14:31.426237Z","iopub.status.idle":"2024-12-04T02:14:31.871641Z","shell.execute_reply.started":"2024-12-04T02:14:31.426202Z","shell.execute_reply":"2024-12-04T02:14:31.870547Z"}},"outputs":[{"name":"stdout","text":"mean prediction: 1.0\n(test) recall: 1.0000\n(test) precision: 0.0563\n(test) BEST threshold: 0.0000\n(test) BEST f1: 0.1066\n(test) BEST recall: 1.0000\n(test) BEST precision: 0.0563\nTest score before training: 0.0563\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"task_type","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"hPKaXrPcHPEt","outputId":"ab418de1-3b4f-4e9e-9ac2-58ec5461d74b","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:31.873731Z","iopub.execute_input":"2024-12-04T02:14:31.874560Z","iopub.status.idle":"2024-12-04T02:14:31.880834Z","shell.execute_reply.started":"2024-12-04T02:14:31.874506Z","shell.execute_reply":"2024-12-04T02:14:31.879668Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'classification'"},"metadata":{}}],"execution_count":68},{"cell_type":"markdown","source":"# Training","metadata":{"id":"kOisJ_blB4uM"}},{"cell_type":"code","source":"def print_grad_norms(model):\n    total_norm = 0.0\n    for p in model.parameters():\n        if p.grad is not None:\n            param_norm = p.grad.data.norm(2)  # L2 norm of the gradient\n            total_norm += param_norm.item() ** 2  # Accumulate squared norms\n\n    total_norm = total_norm ** 0.5  # Final L2 norm across all parameters\n    print(f\"Gradient Norm: {total_norm:.4f}\")","metadata":{"id":"fbjltKw_NXCW","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:33.289463Z","iopub.execute_input":"2024-12-04T02:14:33.290378Z","iopub.status.idle":"2024-12-04T02:14:33.296105Z","shell.execute_reply.started":"2024-12-04T02:14:33.290338Z","shell.execute_reply":"2024-12-04T02:14:33.295039Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"import gc \n\ndef check_cuda_memory():\n    if not torch.cuda.is_available():\n        return {\"error\": \"CUDA is not available on this system.\"}\n\n    device = torch.device(\"cuda\")  # Assumes the first GPU (index 0) is used\n    total_memory = torch.cuda.get_device_properties(device).total_memory\n    allocated_memory = torch.cuda.memory_allocated(device)\n    cached_memory = torch.cuda.memory_reserved(device)\n\n    memory_info = {\n        \"Total Memory (MB)\": total_memory / 1024**2,\n        \"Allocated Memory (MB)\": allocated_memory / 1024**2,\n        \"Cached Memory (MB)\": cached_memory / 1024**2,\n        \"Free Memory (MB)\": (total_memory - cached_memory) / 1024**2,\n    }\n\n    print()\n    for key, value in memory_info.items():\n        print(f\"{key}: {value:.2f} MB\")\n    print()\n\n    return memory_info\n\ndef clear_cuda_cache():\n    if not torch.cuda.is_available():\n        return {\"error\": \"CUDA is not available on this system.\"}\n\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(\"Cleaned cuda cache!\")\n\nclear_cuda_cache()\ncheck_cuda_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:33.760755Z","iopub.execute_input":"2024-12-04T02:14:33.761148Z","iopub.status.idle":"2024-12-04T02:14:34.049051Z","shell.execute_reply.started":"2024-12-04T02:14:33.761114Z","shell.execute_reply":"2024-12-04T02:14:34.048048Z"}},"outputs":[{"name":"stdout","text":"Cleaned cuda cache!\n\nTotal Memory (MB): 16269.25 MB\nAllocated Memory (MB): 85.16 MB\nCached Memory (MB): 120.00 MB\nFree Memory (MB): 16149.25 MB\n\n","output_type":"stream"},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"{'Total Memory (MB)': 16269.25,\n 'Allocated Memory (MB)': 85.16357421875,\n 'Cached Memory (MB)': 120.0,\n 'Free Memory (MB)': 16149.25}"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"# For demonstration purposes (fast training and bad performance),\n# one can set smaller values:\n# n_epochs = 20\n# patience = 2\nn_epochs = 180\npatience = 180\n\nl1_lambda = 1e-8\n\nbatch_size = 8 * 1024\nepoch_size = math.ceil(len(train_idx) / batch_size)\nbest = {\n    'val': -math.inf,\n    'test': -math.inf,\n    'epoch': -1,\n}\n# Early stopping: the training stops when\n# there are more than `patience` consequtive bad updates.\n# patience = 16\nremaining_patience = patience\n\nprint('-' * 88 + '\\n')\nfor epoch in range(n_epochs):\n    loss_avg = 0.0\n    loss_pure_avg = 0.0\n    cnt_samples = 0\n\n    cur_scheduler = scheduler # if epoch < 10 else scheduler\n\n    for batch_idx in tqdm(\n        torch.randperm(len(data['train']['y']), device=device).split(batch_size),\n        desc=f'Epoch {epoch}',\n        total=epoch_size,\n    ):\n\n        # print(batch_idx.shape)\n        model.train()\n        optimizer.zero_grad()\n        Y_train_pred = apply_model(model, 'train', batch_idx)\n        # print(Y_train_pred.shape, Y_train[batch_idx].shape)\n        # print(Y_train_pred.dtype, Y_train[batch_idx].dtype)\n        # Y_train_pred = Y_train_pred.mean(1)\n        loss = loss_fn(Y_train_pred, Y_train[batch_idx].float())\n\n        l1_penalty = 0\n        for param in model.parameters():\n            l1_penalty += torch.sum(torch.abs(param))\n    \n        loss_pure_avg += loss.detach()\n        \n        loss = loss + l1_lambda * l1_penalty\n\n        loss_avg += loss.detach()\n        cnt_samples += 1\n\n        if grad_scaler is None:\n            loss.backward()\n            # print_grad_norms(model)\n            optimizer.step()\n        else:\n            # print('hui')\n            grad_scaler.scale(loss).backward()  # type: ignore\n            grad_scaler.step(cur_optimizer)\n            grad_scaler.update()\n\n    cur_scheduler.step()\n    print(f'AVG EPOCH LOSS: {loss_avg / cnt_samples}')\n    print(f'AVG PURE EPOCH LOSS: {loss_pure_avg / cnt_samples}')\n    print(f'LR: {scheduler.get_last_lr()[0]:.4f}')\n\n    val_score = evaluate(model, 'val')\n    test_score = evaluate(model, 'test')\n    print(f'(val) {val_score:.4f} (test) {test_score:.4f}')\n\n    if val_score > best['val']:\n        print('🌸 New best epoch! 🌸')\n        best = {'val': val_score, 'test': test_score, 'epoch': epoch}\n        remaining_patience = patience\n    else:\n        remaining_patience -= 1\n\n    if remaining_patience < 0:\n        break\n\n    print()\n    if epoch % 10 == 0:\n        print(evaluate(model, 'train'))\n\n    # if epoch >= 2:\n    #     swa_model.update_parameters(model)\n    #     if epoch % 10 == 0:\n    #         print('SWA MODEL EVALUATION:')\n    #         print(evaluate(swa_model, 'train'))\n    #         print(evaluate(swa_model, 'val'))\n    #         print(evaluate(swa_model, 'test'))\n\n    print()\n\nprint('\\n\\nResult:')\nprint(best)\n\n\n# UPDATE BATCH NORM \n# swa_model.train()\n# for batch_idx in tqdm(\n#     torch.randperm(len(data['train']['y']), device=device).split(batch_size),\n# ):\n#     pred = model(data['train']['x_cont'][batch_idx], data['train']['x_cat'][batch_idx])\n\n\n\n# Save the SWA model\ntorch.save(model.state_dict(), \"model.pth\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnZpTVemB4uM","outputId":"9f9981f5-c070-413e-e650-1c0ae091f939","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:14:37.502964Z","iopub.execute_input":"2024-12-04T02:14:37.503388Z","iopub.status.idle":"2024-12-04T02:23:46.306550Z","shell.execute_reply.started":"2024-12-04T02:14:37.503349Z","shell.execute_reply":"2024-12-04T02:23:46.305015Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------------------------------\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.03584987297654152\nAVG PURE EPOCH LOSS: 0.03482028841972351\nLR: 0.0020\nmean prediction: 0.004557405784399649\n(val) recall: 0.0521\n(val) precision: 0.6154\n(val) BEST threshold: 0.4167\n(val) BEST f1: 0.4586\n(val) BEST recall: 0.5136\n(val) BEST precision: 0.4142\nmean prediction: 0.0043121581825830875\n(test) recall: 0.0411\n(test) precision: 0.5366\n(test) BEST threshold: 0.4167\n(test) BEST f1: 0.4605\n(test) BEST recall: 0.5145\n(test) BEST precision: 0.4168\n(val) 0.9472 (test) 0.9440\n🌸 New best epoch! 🌸\n\nmean prediction: 0.004226559152350901\n(train) recall: 0.0472\n(train) precision: 0.6221\n(train) BEST threshold: 0.4167\n(train) BEST f1: 0.4511\n(train) BEST recall: 0.5038\n(train) BEST precision: 0.4084\n0.9453274122550738\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 19/19 [00:03<00:00,  5.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.025726275518536568\nAVG PURE EPOCH LOSS: 0.02469715103507042\nLR: 0.0020\nmean prediction: 0.05714285714285714\n(val) recall: 0.5060\n(val) precision: 0.4765\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4908\n(val) BEST recall: 0.5060\n(val) BEST precision: 0.4765\nmean prediction: 0.06089608750525873\n(test) recall: 0.4921\n(test) precision: 0.4551\n(test) BEST threshold: 0.4583\n(test) BEST f1: 0.4779\n(test) BEST recall: 0.5201\n(test) BEST precision: 0.4421\n(val) 0.9435 (test) 0.9382\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.024322429671883583\nAVG PURE EPOCH LOSS: 0.023295124992728233\nLR: 0.0020\nmean prediction: 0.060648553900087644\n(val) recall: 0.5255\n(val) precision: 0.4663\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4941\n(val) BEST recall: 0.5255\n(val) BEST precision: 0.4663\nmean prediction: 0.06473496003365586\n(test) recall: 0.5135\n(test) precision: 0.4468\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4778\n(test) BEST recall: 0.5135\n(test) BEST precision: 0.4468\n(val) 0.9421 (test) 0.9368\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02401909977197647\nAVG PURE EPOCH LOSS: 0.022994987666606903\nLR: 0.0020\nmean prediction: 0.06281040023371312\n(val) recall: 0.5375\n(val) precision: 0.4605\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4960\n(val) BEST recall: 0.5375\n(val) BEST precision: 0.4605\nmean prediction: 0.06673327724021877\n(test) recall: 0.5229\n(test) precision: 0.4413\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4786\n(test) BEST recall: 0.5229\n(test) BEST precision: 0.4413\n(val) 0.9412 (test) 0.9358\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023880617693066597\nAVG PURE EPOCH LOSS: 0.022860346361994743\nLR: 0.0020\nmean prediction: 0.05930470347648262\n(val) recall: 0.5179\n(val) precision: 0.4700\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4928\n(val) BEST recall: 0.5179\n(val) BEST precision: 0.4700\nmean prediction: 0.06378838872528397\n(test) recall: 0.5079\n(test) precision: 0.4485\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4775\n(test) BEST recall: 0.4865\n(test) BEST precision: 0.4689\n(val) 0.9426 (test) 0.9371\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023853909224271774\nAVG PURE EPOCH LOSS: 0.022837450727820396\nLR: 0.0020\nmean prediction: 0.06088226701723634\n(val) recall: 0.5233\n(val) precision: 0.4626\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4911\n(val) BEST recall: 0.5233\n(val) BEST precision: 0.4626\nmean prediction: 0.06547118216238956\n(test) recall: 0.5191\n(test) precision: 0.4466\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4815\n(test) BEST recall: 0.4874\n(test) BEST precision: 0.4758\n(val) 0.9416 (test) 0.9367\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023785337805747986\nAVG PURE EPOCH LOSS: 0.022772638127207756\nLR: 0.0020\nmean prediction: 0.06140812153082092\n(val) recall: 0.5309\n(val) precision: 0.4653\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4959\n(val) BEST recall: 0.5309\n(val) BEST precision: 0.4653\nmean prediction: 0.06568153134202777\n(test) recall: 0.5163\n(test) precision: 0.4428\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4771\n(test) BEST recall: 0.4911\n(test) BEST precision: 0.4638\n(val) 0.9419 (test) 0.9362\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.0237498227506876\nAVG PURE EPOCH LOSS: 0.022740734741091728\nLR: 0.0020\nmean prediction: 0.06140812153082092\n(val) recall: 0.5299\n(val) precision: 0.4643\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4949\n(val) BEST recall: 0.5299\n(val) BEST precision: 0.4643\nmean prediction: 0.06541859486748001\n(test) recall: 0.5154\n(test) precision: 0.4437\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4782\n(test) BEST recall: 0.4921\n(test) BEST precision: 0.4651\n(val) 0.9418 (test) 0.9363\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02372337505221367\nAVG PURE EPOCH LOSS: 0.022717630490660667\nLR: 0.0020\nmean prediction: 0.06473853345018989\n(val) recall: 0.5505\n(val) precision: 0.4576\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4998\n(val) BEST recall: 0.5505\n(val) BEST precision: 0.4576\nmean prediction: 0.06804795961295751\n(test) recall: 0.5229\n(test) precision: 0.4328\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4785\n(test) BEST recall: 0.4995\n(test) BEST precision: 0.4592\n(val) 0.9407 (test) 0.9345\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 19/19 [00:03<00:00,  5.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023643331602215767\nAVG PURE EPOCH LOSS: 0.02264082059264183\nLR: 0.0020\nmean prediction: 0.06123283669295939\n(val) recall: 0.5288\n(val) precision: 0.4647\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4947\n(val) BEST recall: 0.5288\n(val) BEST precision: 0.4647\nmean prediction: 0.06515565839293226\n(test) recall: 0.5154\n(test) precision: 0.4455\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4809\n(test) BEST recall: 0.4883\n(test) BEST precision: 0.4737\n(val) 0.9419 (test) 0.9366\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02358904853463173\nAVG PURE EPOCH LOSS: 0.02258962020277977\nLR: 0.0020\nmean prediction: 0.06205083260297984\n(val) recall: 0.5309\n(val) precision: 0.4605\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4932\n(val) BEST recall: 0.5309\n(val) BEST precision: 0.4605\nmean prediction: 0.06662810265039966\n(test) recall: 0.5191\n(test) precision: 0.4388\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4805\n(test) BEST recall: 0.4762\n(test) BEST precision: 0.4848\n(val) 0.9413 (test) 0.9355\n\nmean prediction: 0.06557334475997559\n(train) recall: 0.5263\n(train) precision: 0.4471\n(train) BEST threshold: 0.5000\n(train) BEST f1: 0.4835\n(train) BEST recall: 0.5263\n(train) BEST precision: 0.4471\n0.9373612247282926\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 19/19 [00:03<00:00,  5.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023568304255604744\nAVG PURE EPOCH LOSS: 0.022571787238121033\nLR: 0.0020\nmean prediction: 0.06438796377446684\n(val) recall: 0.5472\n(val) precision: 0.4574\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4983\n(val) BEST recall: 0.5472\n(val) BEST precision: 0.4574\nmean prediction: 0.0674169120740429\n(test) recall: 0.5219\n(test) precision: 0.4360\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4778\n(test) BEST recall: 0.5014\n(test) BEST precision: 0.4562\n(val) 0.9407 (test) 0.9351\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 19/19 [00:03<00:00,  5.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023576844483613968\nAVG PURE EPOCH LOSS: 0.02258284017443657\nLR: 0.0020\nmean prediction: 0.06170026292725679\n(val) recall: 0.5309\n(val) precision: 0.4631\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4947\n(val) BEST recall: 0.5309\n(val) BEST precision: 0.4631\nmean prediction: 0.06562894404711822\n(test) recall: 0.5163\n(test) precision: 0.4431\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4793\n(test) BEST recall: 0.4855\n(test) BEST precision: 0.4732\n(val) 0.9416 (test) 0.9362\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 19/19 [00:03<00:00,  5.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023485388606786728\nAVG PURE EPOCH LOSS: 0.022493919357657433\nLR: 0.0020\nmean prediction: 0.06158340636868244\n(val) recall: 0.5309\n(val) precision: 0.4639\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4952\n(val) BEST recall: 0.5309\n(val) BEST precision: 0.4639\nmean prediction: 0.06526083298275137\n(test) recall: 0.5135\n(test) precision: 0.4432\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4783\n(test) BEST recall: 0.4930\n(test) BEST precision: 0.4644\n(val) 0.9417 (test) 0.9363\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023438559845089912\nAVG PURE EPOCH LOSS: 0.022449400275945663\nLR: 0.0020\nmean prediction: 0.0652059596844873\n(val) recall: 0.5516\n(val) precision: 0.4552\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4988\n(val) BEST recall: 0.5516\n(val) BEST precision: 0.4552\nmean prediction: 0.06904711821623896\n(test) recall: 0.5257\n(test) precision: 0.4288\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4781\n(test) BEST recall: 0.4949\n(test) BEST precision: 0.4625\n(val) 0.9403 (test) 0.9338\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023487193509936333\nAVG PURE EPOCH LOSS: 0.02249993197619915\nLR: 0.0020\nmean prediction: 0.06479696172947706\n(val) recall: 0.5483\n(val) precision: 0.4554\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4975\n(val) BEST recall: 0.5483\n(val) BEST precision: 0.4554\nmean prediction: 0.06936264198569625\n(test) recall: 0.5238\n(test) precision: 0.4253\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4844\n(test) BEST recall: 0.4930\n(test) BEST precision: 0.4761\n(val) 0.9404 (test) 0.9333\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02342694252729416\nAVG PURE EPOCH LOSS: 0.02244146727025509\nLR: 0.0020\nmean prediction: 0.06023955594507742\n(val) recall: 0.5223\n(val) precision: 0.4665\n(val) BEST threshold: 0.4583\n(val) BEST f1: 0.4939\n(val) BEST recall: 0.5700\n(val) BEST precision: 0.4357\nmean prediction: 0.06489272191838452\n(test) recall: 0.5107\n(test) precision: 0.4433\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4813\n(test) BEST recall: 0.4865\n(test) BEST precision: 0.4762\n(val) 0.9422 (test) 0.9363\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023315323516726494\nAVG PURE EPOCH LOSS: 0.022331522777676582\nLR: 0.0020\nmean prediction: 0.06053169734151329\n(val) recall: 0.5244\n(val) precision: 0.4662\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4936\n(val) BEST recall: 0.5244\n(val) BEST precision: 0.4662\nmean prediction: 0.06462978544383677\n(test) recall: 0.5117\n(test) precision: 0.4459\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4822\n(test) BEST recall: 0.4855\n(test) BEST precision: 0.4788\n(val) 0.9421 (test) 0.9367\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 19/19 [00:03<00:00,  5.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02325759269297123\nAVG PURE EPOCH LOSS: 0.022275052964687347\nLR: 0.0020\nmean prediction: 0.06222611744084137\n(val) recall: 0.5342\n(val) precision: 0.4620\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4955\n(val) BEST recall: 0.5342\n(val) BEST precision: 0.4620\nmean prediction: 0.06699621371476651\n(test) recall: 0.5201\n(test) precision: 0.4372\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4829\n(test) BEST recall: 0.4874\n(test) BEST precision: 0.4785\n(val) 0.9415 (test) 0.9353\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023228874430060387\nAVG PURE EPOCH LOSS: 0.022247210144996643\nLR: 0.0020\nmean prediction: 0.06012269938650307\n(val) recall: 0.5212\n(val) precision: 0.4665\n(val) BEST threshold: 0.4583\n(val) BEST f1: 0.4927\n(val) BEST recall: 0.5668\n(val) BEST precision: 0.4357\nmean prediction: 0.06457719814892722\n(test) recall: 0.5117\n(test) precision: 0.4463\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4821\n(test) BEST recall: 0.4837\n(test) BEST precision: 0.4805\n(val) 0.9422 (test) 0.9367\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023150520399212837\nAVG PURE EPOCH LOSS: 0.02216971293091774\nLR: 0.0019\nmean prediction: 0.06316096990943616\n(val) recall: 0.5418\n(val) precision: 0.4616\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4985\n(val) BEST recall: 0.5418\n(val) BEST precision: 0.4616\nmean prediction: 0.06673327724021877\n(test) recall: 0.5191\n(test) precision: 0.4381\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4794\n(test) BEST recall: 0.4949\n(test) BEST precision: 0.4649\n(val) 0.9413 (test) 0.9354\n\nmean prediction: 0.0661641541038526\n(train) recall: 0.5328\n(train) precision: 0.4485\n(train) BEST threshold: 0.5000\n(train) BEST f1: 0.4870\n(train) BEST recall: 0.5328\n(train) BEST precision: 0.4485\n0.9374845805253659\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|██████████| 19/19 [00:03<00:00,  5.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02311922423541546\nAVG PURE EPOCH LOSS: 0.022138943895697594\nLR: 0.0019\nmean prediction: 0.06099912357581069\n(val) recall: 0.5288\n(val) precision: 0.4665\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4957\n(val) BEST recall: 0.5288\n(val) BEST precision: 0.4665\nmean prediction: 0.06515565839293226\n(test) recall: 0.5145\n(test) precision: 0.4447\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4796\n(test) BEST recall: 0.4939\n(test) BEST precision: 0.4661\n(val) 0.9421 (test) 0.9365\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.023084517568349838\nAVG PURE EPOCH LOSS: 0.022104529663920403\nLR: 0.0019\nmean prediction: 0.05959684487291849\n(val) recall: 0.5190\n(val) precision: 0.4686\n(val) BEST threshold: 0.4583\n(val) BEST f1: 0.4941\n(val) BEST recall: 0.5646\n(val) BEST precision: 0.4392\nmean prediction: 0.06410391249474127\n(test) recall: 0.5098\n(test) precision: 0.4479\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4808\n(test) BEST recall: 0.4790\n(test) BEST precision: 0.4826\n(val) 0.9424 (test) 0.9370\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23: 100%|██████████| 19/19 [00:03<00:00,  5.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02297031320631504\nAVG PURE EPOCH LOSS: 0.021990662440657616\nLR: 0.0019\nmean prediction: 0.06561495763949751\n(val) recall: 0.5527\n(val) precision: 0.4533\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4980\n(val) BEST recall: 0.5527\n(val) BEST precision: 0.4533\nmean prediction: 0.0699411022297013\n(test) recall: 0.5322\n(test) precision: 0.4286\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4800\n(test) BEST recall: 0.5033\n(test) BEST precision: 0.4587\n(val) 0.9401 (test) 0.9337\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02295820042490959\nAVG PURE EPOCH LOSS: 0.02197839505970478\nLR: 0.0019\nmean prediction: 0.06643295354951796\n(val) recall: 0.5516\n(val) precision: 0.4468\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4937\n(val) BEST recall: 0.5516\n(val) BEST precision: 0.4468\nmean prediction: 0.07136095919225915\n(test) recall: 0.5350\n(test) precision: 0.4223\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4792\n(test) BEST recall: 0.4958\n(test) BEST precision: 0.4638\n(val) 0.9391 (test) 0.9326\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02283485420048237\nAVG PURE EPOCH LOSS: 0.02185489609837532\nLR: 0.0019\nmean prediction: 0.06374525270230792\n(val) recall: 0.5385\n(val) precision: 0.4546\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4930\n(val) BEST recall: 0.5385\n(val) BEST precision: 0.4546\nmean prediction: 0.06778502313840976\n(test) recall: 0.5219\n(test) precision: 0.4337\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4816\n(test) BEST recall: 0.4837\n(test) BEST precision: 0.4796\n(val) 0.9404 (test) 0.9347\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022838538512587547\nAVG PURE EPOCH LOSS: 0.02185824140906334\nLR: 0.0019\nmean prediction: 0.06292725679228747\n(val) recall: 0.5364\n(val) precision: 0.4587\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4945\n(val) BEST recall: 0.5364\n(val) BEST precision: 0.4587\nmean prediction: 0.06778502313840976\n(test) recall: 0.5229\n(test) precision: 0.4344\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4804\n(test) BEST recall: 0.4911\n(test) BEST precision: 0.4701\n(val) 0.9410 (test) 0.9348\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022715693339705467\nAVG PURE EPOCH LOSS: 0.021734880283474922\nLR: 0.0019\nmean prediction: 0.06374525270230792\n(val) recall: 0.5385\n(val) precision: 0.4546\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4930\n(val) BEST recall: 0.5385\n(val) BEST precision: 0.4546\nmean prediction: 0.06825830879259571\n(test) recall: 0.5238\n(test) precision: 0.4322\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4823\n(test) BEST recall: 0.4893\n(test) BEST precision: 0.4755\n(val) 0.9404 (test) 0.9344\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022670404985547066\nAVG PURE EPOCH LOSS: 0.021688882261514664\nLR: 0.0019\nmean prediction: 0.06579024247735904\n(val) recall: 0.5527\n(val) precision: 0.4520\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4973\n(val) BEST recall: 0.5527\n(val) BEST precision: 0.4520\nmean prediction: 0.06988851493479176\n(test) recall: 0.5313\n(test) precision: 0.4281\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4787\n(test) BEST recall: 0.4977\n(test) BEST precision: 0.4611\n(val) 0.9399 (test) 0.9336\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022595206275582314\nAVG PURE EPOCH LOSS: 0.021612998098134995\nLR: 0.0019\nmean prediction: 0.059830557990067194\n(val) recall: 0.5190\n(val) precision: 0.4668\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4915\n(val) BEST recall: 0.5190\n(val) BEST precision: 0.4668\nmean prediction: 0.06415649978965082\n(test) recall: 0.5117\n(test) precision: 0.4492\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4791\n(test) BEST recall: 0.4715\n(test) BEST precision: 0.4870\n(val) 0.9422 (test) 0.9372\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022528769448399544\nAVG PURE EPOCH LOSS: 0.02154594659805298\nLR: 0.0019\nmean prediction: 0.0638036809815951\n(val) recall: 0.5385\n(val) precision: 0.4542\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4928\n(val) BEST recall: 0.5385\n(val) BEST precision: 0.4542\nmean prediction: 0.06799537231804796\n(test) recall: 0.5238\n(test) precision: 0.4339\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4803\n(test) BEST recall: 0.4883\n(test) BEST precision: 0.4724\n(val) 0.9403 (test) 0.9347\n\nmean prediction: 0.06711204601820472\n(train) recall: 0.5498\n(train) precision: 0.4563\n(train) BEST threshold: 0.5000\n(train) BEST f1: 0.4987\n(train) BEST recall: 0.5498\n(train) BEST precision: 0.4563\n0.938432472439718\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022387398406863213\nAVG PURE EPOCH LOSS: 0.021403687074780464\nLR: 0.0019\nmean prediction: 0.06409582237803096\n(val) recall: 0.5407\n(val) precision: 0.4540\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4936\n(val) BEST recall: 0.5407\n(val) BEST precision: 0.4540\nmean prediction: 0.06867900715187211\n(test) recall: 0.5257\n(test) precision: 0.4311\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4793\n(test) BEST recall: 0.4967\n(test) BEST precision: 0.4630\n(val) 0.9403 (test) 0.9342\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022331293672323227\nAVG PURE EPOCH LOSS: 0.021346580237150192\nLR: 0.0019\nmean prediction: 0.06152497808939527\n(val) recall: 0.5255\n(val) precision: 0.4596\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4904\n(val) BEST recall: 0.5255\n(val) BEST precision: 0.4596\nmean prediction: 0.06636516617585192\n(test) recall: 0.5173\n(test) precision: 0.4390\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4790\n(test) BEST recall: 0.4855\n(test) BEST precision: 0.4727\n(val) 0.9412 (test) 0.9356\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02226979099214077\nAVG PURE EPOCH LOSS: 0.021283911541104317\nLR: 0.0019\nmean prediction: 0.06012269938650307\n(val) recall: 0.5179\n(val) precision: 0.4636\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4892\n(val) BEST recall: 0.5179\n(val) BEST precision: 0.4636\nmean prediction: 0.06426167437946992\n(test) recall: 0.5117\n(test) precision: 0.4484\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4795\n(test) BEST recall: 0.4697\n(test) BEST precision: 0.4898\n(val) 0.9418 (test) 0.9371\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022188261151313782\nAVG PURE EPOCH LOSS: 0.02120121195912361\nLR: 0.0019\nmean prediction: 0.06397896581945661\n(val) recall: 0.5342\n(val) precision: 0.4493\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4881\n(val) BEST recall: 0.5342\n(val) BEST precision: 0.4493\nmean prediction: 0.06825830879259571\n(test) recall: 0.5238\n(test) precision: 0.4322\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4791\n(test) BEST recall: 0.4921\n(test) BEST precision: 0.4668\n(val) 0.9397 (test) 0.9344\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022129449993371964\nAVG PURE EPOCH LOSS: 0.02114112488925457\nLR: 0.0018\nmean prediction: 0.06392053754016944\n(val) recall: 0.5364\n(val) precision: 0.4516\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4904\n(val) BEST recall: 0.4984\n(val) BEST precision: 0.4826\nmean prediction: 0.06867900715187211\n(test) recall: 0.5238\n(test) precision: 0.4296\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4793\n(test) BEST recall: 0.4921\n(test) BEST precision: 0.4672\n(val) 0.9400 (test) 0.9340\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.022040944546461105\nAVG PURE EPOCH LOSS: 0.021051324903964996\nLR: 0.0018\nmean prediction: 0.06584867075664622\n(val) recall: 0.5451\n(val) precision: 0.4454\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4902\n(val) BEST recall: 0.5451\n(val) BEST precision: 0.4454\nmean prediction: 0.07020403870424906\n(test) recall: 0.5313\n(test) precision: 0.4262\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4783\n(test) BEST recall: 0.4930\n(test) BEST precision: 0.4644\n(val) 0.9390 (test) 0.9333\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021940158680081367\nAVG PURE EPOCH LOSS: 0.020949307829141617\nLR: 0.0018\nmean prediction: 0.0638036809815951\n(val) recall: 0.5320\n(val) precision: 0.4487\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4868\n(val) BEST recall: 0.5320\n(val) BEST precision: 0.4487\nmean prediction: 0.0688893563315103\n(test) recall: 0.5266\n(test) precision: 0.4305\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4761\n(test) BEST recall: 0.4874\n(test) BEST precision: 0.4652\n(val) 0.9396 (test) 0.9341\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021860135719180107\nAVG PURE EPOCH LOSS: 0.02086770534515381\nLR: 0.0018\nmean prediction: 0.06076541045866199\n(val) recall: 0.5201\n(val) precision: 0.4606\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4912\n(val) BEST recall: 0.4832\n(val) BEST precision: 0.4994\nmean prediction: 0.06515565839293226\n(test) recall: 0.5117\n(test) precision: 0.4423\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4759\n(test) BEST recall: 0.4706\n(test) BEST precision: 0.4814\n(val) 0.9414 (test) 0.9362\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02183595485985279\nAVG PURE EPOCH LOSS: 0.020842045545578003\nLR: 0.0018\nmean prediction: 0.06216768916155419\n(val) recall: 0.5266\n(val) precision: 0.4558\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4916\n(val) BEST recall: 0.4940\n(val) BEST precision: 0.4892\nmean prediction: 0.06699621371476651\n(test) recall: 0.5191\n(test) precision: 0.4364\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4802\n(test) BEST recall: 0.4874\n(test) BEST precision: 0.4733\n(val) 0.9407 (test) 0.9352\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021761668846011162\nAVG PURE EPOCH LOSS: 0.02076631598174572\nLR: 0.0018\nmean prediction: 0.06625766871165645\n(val) recall: 0.5440\n(val) precision: 0.4418\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4899\n(val) BEST recall: 0.5027\n(val) BEST precision: 0.4778\nmean prediction: 0.0704669751787968\n(test) recall: 0.5322\n(test) precision: 0.4254\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4783\n(test) BEST recall: 0.4939\n(test) BEST precision: 0.4636\n(val) 0.9385 (test) 0.9332\n\nmean prediction: 0.06973497980860374\n(train) recall: 0.5816\n(train) precision: 0.4646\n(train) BEST threshold: 0.4583\n(train) BEST f1: 0.5189\n(train) BEST recall: 0.6538\n(train) BEST precision: 0.4301\n0.939354394712581\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|██████████| 19/19 [00:03<00:00,  5.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021658824756741524\nAVG PURE EPOCH LOSS: 0.0206619780510664\nLR: 0.0018\nmean prediction: 0.06485539000876424\n(val) recall: 0.5353\n(val) precision: 0.4441\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4887\n(val) BEST recall: 0.5060\n(val) BEST precision: 0.4726\nmean prediction: 0.06999368952461085\n(test) recall: 0.5322\n(test) precision: 0.4282\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4812\n(test) BEST recall: 0.5014\n(test) BEST precision: 0.4625\n(val) 0.9389 (test) 0.9336\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02154521644115448\nAVG PURE EPOCH LOSS: 0.02054678089916706\nLR: 0.0018\nmean prediction: 0.06374525270230792\n(val) recall: 0.5309\n(val) precision: 0.4482\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4911\n(val) BEST recall: 0.5081\n(val) BEST precision: 0.4751\nmean prediction: 0.0681531342027766\n(test) recall: 0.5229\n(test) precision: 0.4321\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4784\n(test) BEST recall: 0.4967\n(test) BEST precision: 0.4614\n(val) 0.9396 (test) 0.9344\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021453315392136574\nAVG PURE EPOCH LOSS: 0.020453356206417084\nLR: 0.0018\nmean prediction: 0.06421267893660532\n(val) recall: 0.5309\n(val) precision: 0.4449\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4865\n(val) BEST recall: 0.4875\n(val) BEST precision: 0.4854\nmean prediction: 0.06841607067732436\n(test) recall: 0.5182\n(test) precision: 0.4266\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4744\n(test) BEST recall: 0.4809\n(test) BEST precision: 0.4682\n(val) 0.9391 (test) 0.9336\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02140350081026554\nAVG PURE EPOCH LOSS: 0.020401816815137863\nLR: 0.0018\nmean prediction: 0.062109260882267016\n(val) recall: 0.5233\n(val) precision: 0.4534\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4873\n(val) BEST recall: 0.4897\n(val) BEST precision: 0.4849\nmean prediction: 0.06636516617585192\n(test) recall: 0.5154\n(test) precision: 0.4374\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4775\n(test) BEST recall: 0.4846\n(test) BEST precision: 0.4705\n(val) 0.9404 (test) 0.9354\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45: 100%|██████████| 19/19 [00:03<00:00,  5.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021332090720534325\nAVG PURE EPOCH LOSS: 0.020328667014837265\nLR: 0.0018\nmean prediction: 0.06310254163014899\n(val) recall: 0.5255\n(val) precision: 0.4481\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4906\n(val) BEST recall: 0.4973\n(val) BEST precision: 0.4841\nmean prediction: 0.06804795961295751\n(test) recall: 0.5210\n(test) precision: 0.4312\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4795\n(test) BEST recall: 0.4902\n(test) BEST precision: 0.4692\n(val) 0.9396 (test) 0.9343\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021230380982160568\nAVG PURE EPOCH LOSS: 0.020225215703248978\nLR: 0.0017\nmean prediction: 0.06263511539585159\n(val) recall: 0.5255\n(val) precision: 0.4515\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4881\n(val) BEST recall: 0.4919\n(val) BEST precision: 0.4845\nmean prediction: 0.06704880100967606\n(test) recall: 0.5173\n(test) precision: 0.4345\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4780\n(test) BEST recall: 0.4874\n(test) BEST precision: 0.4690\n(val) 0.9401 (test) 0.9349\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47: 100%|██████████| 19/19 [00:03<00:00,  5.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.021161755546927452\nAVG PURE EPOCH LOSS: 0.02015487477183342\nLR: 0.0017\nmean prediction: 0.06654981010809231\n(val) recall: 0.5407\n(val) precision: 0.4372\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4869\n(val) BEST recall: 0.5060\n(val) BEST precision: 0.4693\nmean prediction: 0.07115061001262095\n(test) recall: 0.5303\n(test) precision: 0.4198\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4778\n(test) BEST recall: 0.4977\n(test) BEST precision: 0.4595\n(val) 0.9378 (test) 0.9323\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02111455425620079\nAVG PURE EPOCH LOSS: 0.020106103271245956\nLR: 0.0017\nmean prediction: 0.06059012562080047\n(val) recall: 0.5168\n(val) precision: 0.4590\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4862\n(val) BEST recall: 0.5168\n(val) BEST precision: 0.4590\nmean prediction: 0.06420908708456037\n(test) recall: 0.5079\n(test) precision: 0.4455\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4754\n(test) BEST recall: 0.4650\n(test) BEST precision: 0.4863\n(val) 0.9412 (test) 0.9367\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.020998993888497353\nAVG PURE EPOCH LOSS: 0.019988950341939926\nLR: 0.0017\nmean prediction: 0.06327782646801051\n(val) recall: 0.5266\n(val) precision: 0.4478\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4895\n(val) BEST recall: 0.4951\n(val) BEST precision: 0.4841\nmean prediction: 0.06778502313840976\n(test) recall: 0.5182\n(test) precision: 0.4306\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4775\n(test) BEST recall: 0.4855\n(test) BEST precision: 0.4697\n(val) 0.9396 (test) 0.9343\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.020891990512609482\nAVG PURE EPOCH LOSS: 0.01988028921186924\nLR: 0.0017\nmean prediction: 0.06345311130587204\n(val) recall: 0.5277\n(val) precision: 0.4475\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4859\n(val) BEST recall: 0.4853\n(val) BEST precision: 0.4864\nmean prediction: 0.06762726125368111\n(test) recall: 0.5201\n(test) precision: 0.4331\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4741\n(test) BEST recall: 0.4781\n(test) BEST precision: 0.4702\n(val) 0.9395 (test) 0.9346\n\nmean prediction: 0.06730032591900069\n(train) recall: 0.5963\n(train) precision: 0.4935\n(train) BEST threshold: 0.4583\n(train) BEST f1: 0.5532\n(train) BEST recall: 0.6775\n(train) BEST precision: 0.4674\n0.9434251360159973\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.0208449624478817\nAVG PURE EPOCH LOSS: 0.01983151212334633\nLR: 0.0017\nmean prediction: 0.06304411335086181\n(val) recall: 0.5244\n(val) precision: 0.4476\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4839\n(val) BEST recall: 0.4810\n(val) BEST precision: 0.4868\nmean prediction: 0.06746949936895247\n(test) recall: 0.5201\n(test) precision: 0.4341\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4752\n(test) BEST recall: 0.4743\n(test) BEST precision: 0.4761\n(val) 0.9396 (test) 0.9348\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.020770564675331116\nAVG PURE EPOCH LOSS: 0.019755583256483078\nLR: 0.0017\nmean prediction: 0.06205083260297984\n(val) recall: 0.5244\n(val) precision: 0.4548\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4906\n(val) BEST recall: 0.4984\n(val) BEST precision: 0.4832\nmean prediction: 0.06668068994530921\n(test) recall: 0.5173\n(test) precision: 0.4369\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4778\n(test) BEST recall: 0.4874\n(test) BEST precision: 0.4686\n(val) 0.9406 (test) 0.9353\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.020654907450079918\nAVG PURE EPOCH LOSS: 0.019638236612081528\nLR: 0.0017\nmean prediction: 0.06222611744084137\n(val) recall: 0.5223\n(val) precision: 0.4516\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4844\n(val) BEST recall: 0.5223\n(val) BEST precision: 0.4516\nmean prediction: 0.06625999158603281\n(test) recall: 0.5145\n(test) precision: 0.4373\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4741\n(test) BEST recall: 0.4734\n(test) BEST precision: 0.4747\n(val) 0.9402 (test) 0.9354\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.020622212439775467\nAVG PURE EPOCH LOSS: 0.0196039080619812\nLR: 0.0017\nmean prediction: 0.06333625474729769\n(val) recall: 0.5277\n(val) precision: 0.4483\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4909\n(val) BEST recall: 0.4973\n(val) BEST precision: 0.4847\nmean prediction: 0.06831089608750526\n(test) recall: 0.5219\n(test) precision: 0.4303\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4788\n(test) BEST recall: 0.4855\n(test) BEST precision: 0.4723\n(val) 0.9396 (test) 0.9342\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02052422985434532\nAVG PURE EPOCH LOSS: 0.0195043683052063\nLR: 0.0016\nmean prediction: 0.06438796377446684\n(val) recall: 0.5277\n(val) precision: 0.4410\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4821\n(val) BEST recall: 0.4832\n(val) BEST precision: 0.4811\nmean prediction: 0.0689945309213294\n(test) recall: 0.5247\n(test) precision: 0.4284\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4732\n(test) BEST recall: 0.4790\n(test) BEST precision: 0.4676\n(val) 0.9386 (test) 0.9338\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02046521008014679\nAVG PURE EPOCH LOSS: 0.019443675875663757\nLR: 0.0016\nmean prediction: 0.06298568507157465\n(val) recall: 0.5244\n(val) precision: 0.4481\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4884\n(val) BEST recall: 0.4929\n(val) BEST precision: 0.4840\nmean prediction: 0.06704880100967606\n(test) recall: 0.5201\n(test) precision: 0.4369\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4757\n(test) BEST recall: 0.4799\n(test) BEST precision: 0.4716\n(val) 0.9396 (test) 0.9352\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57: 100%|██████████| 19/19 [00:03<00:00,  5.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.020361119881272316\nAVG PURE EPOCH LOSS: 0.019337793812155724\nLR: 0.0016\nmean prediction: 0.061174408413672214\n(val) recall: 0.5179\n(val) precision: 0.4556\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4848\n(val) BEST recall: 0.5179\n(val) BEST precision: 0.4556\nmean prediction: 0.06541859486748001\n(test) recall: 0.5117\n(test) precision: 0.4405\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4734\n(test) BEST recall: 0.5117\n(test) BEST precision: 0.4405\n(val) 0.9408 (test) 0.9359\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02029711753129959\nAVG PURE EPOCH LOSS: 0.019272001460194588\nLR: 0.0016\nmean prediction: 0.06316096990943616\n(val) recall: 0.5223\n(val) precision: 0.4450\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4853\n(val) BEST recall: 0.4940\n(val) BEST precision: 0.4769\nmean prediction: 0.0674169120740429\n(test) recall: 0.5201\n(test) precision: 0.4345\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4783\n(test) BEST recall: 0.4883\n(test) BEST precision: 0.4686\n(val) 0.9392 (test) 0.9348\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.0202023983001709\nAVG PURE EPOCH LOSS: 0.019175395369529724\nLR: 0.0016\nmean prediction: 0.0645048203330412\n(val) recall: 0.5277\n(val) precision: 0.4402\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4846\n(val) BEST recall: 0.4962\n(val) BEST precision: 0.4736\nmean prediction: 0.06936264198569625\n(test) recall: 0.5294\n(test) precision: 0.4299\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4745\n(test) BEST recall: 0.5294\n(test) BEST precision: 0.4299\n(val) 0.9385 (test) 0.9340\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02013246901333332\nAVG PURE EPOCH LOSS: 0.019103536382317543\nLR: 0.0016\nmean prediction: 0.06018112766579024\n(val) recall: 0.5136\n(val) precision: 0.4592\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4899\n(val) BEST recall: 0.4886\n(val) BEST precision: 0.4913\nmean prediction: 0.06462978544383677\n(test) recall: 0.5079\n(test) precision: 0.4426\n(test) BEST threshold: 0.4583\n(test) BEST f1: 0.4732\n(test) BEST recall: 0.5397\n(test) BEST precision: 0.4213\n(val) 0.9413 (test) 0.9363\n\nmean prediction: 0.0652097697791282\n(train) recall: 0.5944\n(train) precision: 0.5078\n(train) BEST threshold: 0.4167\n(train) BEST f1: 0.5887\n(train) BEST recall: 0.7612\n(train) BEST precision: 0.4800\n0.945307935023957\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61: 100%|██████████| 19/19 [00:03<00:00,  5.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.02008843421936035\nAVG PURE EPOCH LOSS: 0.019057704135775566\nLR: 0.0016\nmean prediction: 0.06602395559450774\n(val) recall: 0.5309\n(val) precision: 0.4327\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4885\n(val) BEST recall: 0.5060\n(val) BEST precision: 0.4721\nmean prediction: 0.07072991165334455\n(test) recall: 0.5350\n(test) precision: 0.4260\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4764\n(test) BEST recall: 0.4986\n(test) BEST precision: 0.4560\n(val) 0.9373 (test) 0.9332\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.020008306950330734\nAVG PURE EPOCH LOSS: 0.018975848332047462\nLR: 0.0016\nmean prediction: 0.06456324861232837\n(val) recall: 0.5255\n(val) precision: 0.4380\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4788\n(val) BEST recall: 0.4712\n(val) BEST precision: 0.4865\nmean prediction: 0.06789019772822887\n(test) recall: 0.5229\n(test) precision: 0.4338\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4742\n(test) BEST recall: 0.5229\n(test) BEST precision: 0.4338\n(val) 0.9382 (test) 0.9347\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019948873668909073\nAVG PURE EPOCH LOSS: 0.018914582207798958\nLR: 0.0015\nmean prediction: 0.06362839614373357\n(val) recall: 0.5255\n(val) precision: 0.4444\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4873\n(val) BEST recall: 0.4995\n(val) BEST precision: 0.4757\nmean prediction: 0.0688893563315103\n(test) recall: 0.5247\n(test) precision: 0.4290\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4729\n(test) BEST recall: 0.4883\n(test) BEST precision: 0.4584\n(val) 0.9391 (test) 0.9339\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01988842710852623\nAVG PURE EPOCH LOSS: 0.018852274864912033\nLR: 0.0015\nmean prediction: 0.06508910312591294\n(val) recall: 0.5299\n(val) precision: 0.4381\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4873\n(val) BEST recall: 0.4995\n(val) BEST precision: 0.4757\nmean prediction: 0.06952040387042491\n(test) recall: 0.5257\n(test) precision: 0.4259\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4705\n(test) BEST recall: 0.5257\n(test) BEST precision: 0.4259\n(val) 0.9381 (test) 0.9334\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01980290561914444\nAVG PURE EPOCH LOSS: 0.018764987587928772\nLR: 0.0015\nmean prediction: 0.061933976044405495\n(val) recall: 0.5212\n(val) precision: 0.4528\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4865\n(val) BEST recall: 0.4897\n(val) BEST precision: 0.4834\nmean prediction: 0.06652292806058056\n(test) recall: 0.5145\n(test) precision: 0.4356\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4722\n(test) BEST recall: 0.4753\n(test) BEST precision: 0.4691\n(val) 0.9403 (test) 0.9351\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019721930846571922\nAVG PURE EPOCH LOSS: 0.01868225820362568\nLR: 0.0015\nmean prediction: 0.05907099035933392\n(val) recall: 0.5103\n(val) precision: 0.4649\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4865\n(val) BEST recall: 0.5103\n(val) BEST precision: 0.4649\nmean prediction: 0.06299957930164073\n(test) recall: 0.5005\n(test) precision: 0.4474\n(test) BEST threshold: 0.4583\n(test) BEST f1: 0.4769\n(test) BEST recall: 0.5434\n(test) BEST precision: 0.4248\n(val) 0.9420 (test) 0.9371\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019700318574905396\nAVG PURE EPOCH LOSS: 0.01865900307893753\nLR: 0.0015\nmean prediction: 0.062459830557990065\n(val) recall: 0.5233\n(val) precision: 0.4509\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4844\n(val) BEST recall: 0.5233\n(val) BEST precision: 0.4509\nmean prediction: 0.06662810265039966\n(test) recall: 0.5163\n(test) precision: 0.4365\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4750\n(test) BEST recall: 0.4781\n(test) BEST precision: 0.4719\n(val) 0.9401 (test) 0.9352\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019627539440989494\nAVG PURE EPOCH LOSS: 0.01858457364141941\nLR: 0.0015\nmean prediction: 0.05994741454864154\n(val) recall: 0.5125\n(val) precision: 0.4600\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4859\n(val) BEST recall: 0.4767\n(val) BEST precision: 0.4955\nmean prediction: 0.06394615061001262\n(test) recall: 0.5033\n(test) precision: 0.4433\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4714\n(test) BEST recall: 0.5033\n(test) BEST precision: 0.4433\n(val) 0.9414 (test) 0.9364\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01959255523979664\nAVG PURE EPOCH LOSS: 0.01854785531759262\nLR: 0.0015\nmean prediction: 0.05988898626935437\n(val) recall: 0.5147\n(val) precision: 0.4624\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4872\n(val) BEST recall: 0.5147\n(val) BEST precision: 0.4624\nmean prediction: 0.06373580143037443\n(test) recall: 0.5079\n(test) precision: 0.4488\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4766\n(test) BEST recall: 0.5079\n(test) BEST precision: 0.4488\n(val) 0.9417 (test) 0.9372\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019526660442352295\nAVG PURE EPOCH LOSS: 0.018480217084288597\nLR: 0.0014\nmean prediction: 0.06053169734151329\n(val) recall: 0.5147\n(val) precision: 0.4575\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4883\n(val) BEST recall: 0.4864\n(val) BEST precision: 0.4902\nmean prediction: 0.06484013462347497\n(test) recall: 0.5098\n(test) precision: 0.4428\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4740\n(test) BEST recall: 0.5098\n(test) BEST precision: 0.4428\n(val) 0.9410 (test) 0.9363\n\nmean prediction: 0.06687182683443055\n(train) recall: 0.6401\n(train) precision: 0.5332\n(train) BEST threshold: 0.4167\n(train) BEST f1: 0.6172\n(train) BEST recall: 0.8101\n(train) BEST precision: 0.4985\n0.9487359277005181\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71: 100%|██████████| 19/19 [00:03<00:00,  5.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019461315125226974\nAVG PURE EPOCH LOSS: 0.018413299694657326\nLR: 0.0014\nmean prediction: 0.06070698217937482\n(val) recall: 0.5168\n(val) precision: 0.4581\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4857\n(val) BEST recall: 0.5168\n(val) BEST precision: 0.4581\nmean prediction: 0.06489272191838452\n(test) recall: 0.5126\n(test) precision: 0.4449\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4764\n(test) BEST recall: 0.5126\n(test) BEST precision: 0.4449\n(val) 0.9411 (test) 0.9365\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019423630088567734\nAVG PURE EPOCH LOSS: 0.018374036997556686\nLR: 0.0014\nmean prediction: 0.06409582237803096\n(val) recall: 0.5255\n(val) precision: 0.4412\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4845\n(val) BEST recall: 0.4908\n(val) BEST precision: 0.4783\nmean prediction: 0.06820572149768615\n(test) recall: 0.5229\n(test) precision: 0.4318\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4730\n(test) BEST recall: 0.5229\n(test) BEST precision: 0.4318\n(val) 0.9387 (test) 0.9344\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019330743700265884\nAVG PURE EPOCH LOSS: 0.018279610201716423\nLR: 0.0014\nmean prediction: 0.05977212971078002\n(val) recall: 0.5103\n(val) precision: 0.4594\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4835\n(val) BEST recall: 0.5103\n(val) BEST precision: 0.4594\nmean prediction: 0.06405132519983173\n(test) recall: 0.5070\n(test) precision: 0.4458\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4744\n(test) BEST recall: 0.5070\n(test) BEST precision: 0.4458\n(val) 0.9413 (test) 0.9367\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019331039860844612\nAVG PURE EPOCH LOSS: 0.01827838644385338\nLR: 0.0014\nmean prediction: 0.0635699678644464\n(val) recall: 0.5233\n(val) precision: 0.4430\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4798\n(val) BEST recall: 0.5233\n(val) BEST precision: 0.4430\nmean prediction: 0.0678376104333193\n(test) recall: 0.5201\n(test) precision: 0.4318\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4747\n(test) BEST recall: 0.4809\n(test) BEST precision: 0.4686\n(val) 0.9389 (test) 0.9344\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01924807019531727\nAVG PURE EPOCH LOSS: 0.018194016069173813\nLR: 0.0014\nmean prediction: 0.06392053754016944\n(val) recall: 0.5255\n(val) precision: 0.4424\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4825\n(val) BEST recall: 0.4929\n(val) BEST precision: 0.4724\nmean prediction: 0.06820572149768615\n(test) recall: 0.5210\n(test) precision: 0.4302\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4757\n(test) BEST recall: 0.4883\n(test) BEST precision: 0.4637\n(val) 0.9388 (test) 0.9342\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01917911134660244\nAVG PURE EPOCH LOSS: 0.01812356896698475\nLR: 0.0014\nmean prediction: 0.06170026292725679\n(val) recall: 0.5179\n(val) precision: 0.4517\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4825\n(val) BEST recall: 0.5179\n(val) BEST precision: 0.4517\nmean prediction: 0.06557635675220867\n(test) recall: 0.5145\n(test) precision: 0.4419\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4754\n(test) BEST recall: 0.5145\n(test) BEST precision: 0.4419\n(val) 0.9402 (test) 0.9361\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 77: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019078955054283142\nAVG PURE EPOCH LOSS: 0.018021926283836365\nLR: 0.0013\nmean prediction: 0.06041484078293894\n(val) recall: 0.5125\n(val) precision: 0.4565\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4830\n(val) BEST recall: 0.4777\n(val) BEST precision: 0.4883\nmean prediction: 0.06478754732856541\n(test) recall: 0.5070\n(test) precision: 0.4407\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4716\n(test) BEST recall: 0.5070\n(test) BEST precision: 0.4407\n(val) 0.9409 (test) 0.9360\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 78: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01904262602329254\nAVG PURE EPOCH LOSS: 0.017984136939048767\nLR: 0.0013\nmean prediction: 0.06053169734151329\n(val) recall: 0.5147\n(val) precision: 0.4575\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4844\n(val) BEST recall: 0.5147\n(val) BEST precision: 0.4575\nmean prediction: 0.06436684896928901\n(test) recall: 0.5070\n(test) precision: 0.4436\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4732\n(test) BEST recall: 0.5070\n(test) BEST precision: 0.4436\n(val) 0.9410 (test) 0.9364\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 79: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.019015423953533173\nAVG PURE EPOCH LOSS: 0.017955569550395012\nLR: 0.0013\nmean prediction: 0.06158340636868244\n(val) recall: 0.5201\n(val) precision: 0.4545\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4851\n(val) BEST recall: 0.5201\n(val) BEST precision: 0.4545\nmean prediction: 0.06625999158603281\n(test) recall: 0.5154\n(test) precision: 0.4381\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4736\n(test) BEST recall: 0.5154\n(test) BEST precision: 0.4381\n(val) 0.9406 (test) 0.9355\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 80: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01894858106970787\nAVG PURE EPOCH LOSS: 0.017887359485030174\nLR: 0.0013\nmean prediction: 0.06053169734151329\n(val) recall: 0.5147\n(val) precision: 0.4575\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4844\n(val) BEST recall: 0.5147\n(val) BEST precision: 0.4575\nmean prediction: 0.06462978544383677\n(test) recall: 0.5079\n(test) precision: 0.4426\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4732\n(test) BEST recall: 0.4706\n(test) BEST precision: 0.4759\n(val) 0.9410 (test) 0.9363\n\nmean prediction: 0.0694882682144573\n(train) recall: 0.6988\n(train) precision: 0.5602\n(train) BEST threshold: 0.4167\n(train) BEST f1: 0.6498\n(train) BEST recall: 0.8751\n(train) BEST precision: 0.5168\n0.9526638359757443\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018873633816838264\nAVG PURE EPOCH LOSS: 0.017811087891459465\nLR: 0.0013\nmean prediction: 0.06304411335086181\n(val) recall: 0.5223\n(val) precision: 0.4458\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4828\n(val) BEST recall: 0.4864\n(val) BEST precision: 0.4791\nmean prediction: 0.06662810265039966\n(test) recall: 0.5182\n(test) precision: 0.4380\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4748\n(test) BEST recall: 0.5182\n(test) BEST precision: 0.4380\n(val) 0.9394 (test) 0.9354\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 82: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018862495198845863\nAVG PURE EPOCH LOSS: 0.01779864728450775\nLR: 0.0013\nmean prediction: 0.06275197195442594\n(val) recall: 0.5212\n(val) precision: 0.4469\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4873\n(val) BEST recall: 0.4908\n(val) BEST precision: 0.4839\nmean prediction: 0.06736432477913336\n(test) recall: 0.5210\n(test) precision: 0.4356\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4745\n(test) BEST recall: 0.5210\n(test) BEST precision: 0.4356\n(val) 0.9395 (test) 0.9350\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 83: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01885218918323517\nAVG PURE EPOCH LOSS: 0.017787083983421326\nLR: 0.0013\nmean prediction: 0.06041484078293894\n(val) recall: 0.5147\n(val) precision: 0.4584\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4849\n(val) BEST recall: 0.5147\n(val) BEST precision: 0.4584\nmean prediction: 0.06436684896928901\n(test) recall: 0.5061\n(test) precision: 0.4428\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4723\n(test) BEST recall: 0.5061\n(test) BEST precision: 0.4428\n(val) 0.9412 (test) 0.9363\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 84: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01878458447754383\nAVG PURE EPOCH LOSS: 0.017718231305480003\nLR: 0.0012\nmean prediction: 0.05971370143149284\n(val) recall: 0.5125\n(val) precision: 0.4618\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4858\n(val) BEST recall: 0.5125\n(val) BEST precision: 0.4618\nmean prediction: 0.06352545225073622\n(test) recall: 0.5042\n(test) precision: 0.4470\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4739\n(test) BEST recall: 0.5042\n(test) BEST precision: 0.4470\n(val) 0.9416 (test) 0.9369\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 85: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018739648163318634\nAVG PURE EPOCH LOSS: 0.017672117799520493\nLR: 0.0012\nmean prediction: 0.060648553900087644\n(val) recall: 0.5168\n(val) precision: 0.4586\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4860\n(val) BEST recall: 0.5168\n(val) BEST precision: 0.4586\nmean prediction: 0.06494530921329407\n(test) recall: 0.5107\n(test) precision: 0.4429\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4744\n(test) BEST recall: 0.5107\n(test) BEST precision: 0.4429\n(val) 0.9412 (test) 0.9363\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 86: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018693190068006516\nAVG PURE EPOCH LOSS: 0.01762445829808712\nLR: 0.0012\nmean prediction: 0.06134969325153374\n(val) recall: 0.5168\n(val) precision: 0.4533\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4830\n(val) BEST recall: 0.5168\n(val) BEST precision: 0.4533\nmean prediction: 0.06604964240639462\n(test) recall: 0.5154\n(test) precision: 0.4395\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4744\n(test) BEST recall: 0.5154\n(test) BEST precision: 0.4395\n(val) 0.9405 (test) 0.9357\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 87: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01865031197667122\nAVG PURE EPOCH LOSS: 0.017580455169081688\nLR: 0.0012\nmean prediction: 0.06152497808939527\n(val) recall: 0.5157\n(val) precision: 0.4511\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4827\n(val) BEST recall: 0.4843\n(val) BEST precision: 0.4811\nmean prediction: 0.06678586453512832\n(test) recall: 0.5201\n(test) precision: 0.4386\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4759\n(test) BEST recall: 0.5201\n(test) BEST precision: 0.4386\n(val) 0.9402 (test) 0.9355\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 88: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01861477456986904\nAVG PURE EPOCH LOSS: 0.017543768510222435\nLR: 0.0012\nmean prediction: 0.05971370143149284\n(val) recall: 0.5136\n(val) precision: 0.4628\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4869\n(val) BEST recall: 0.5136\n(val) BEST precision: 0.4628\nmean prediction: 0.06368321413546488\n(test) recall: 0.5042\n(test) precision: 0.4459\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4733\n(test) BEST recall: 0.5042\n(test) BEST precision: 0.4459\n(val) 0.9417 (test) 0.9368\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 89: 100%|██████████| 19/19 [00:03<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018577782437205315\nAVG PURE EPOCH LOSS: 0.017505642026662827\nLR: 0.0012\nmean prediction: 0.06041484078293894\n(val) recall: 0.5136\n(val) precision: 0.4574\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4839\n(val) BEST recall: 0.5136\n(val) BEST precision: 0.4574\nmean prediction: 0.06441943626419858\n(test) recall: 0.5089\n(test) precision: 0.4449\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4747\n(test) BEST recall: 0.5089\n(test) BEST precision: 0.4449\n(val) 0.9410 (test) 0.9366\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 90: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01851605623960495\nAVG PURE EPOCH LOSS: 0.017442811280488968\nLR: 0.0011\nmean prediction: 0.06123283669295939\n(val) recall: 0.5168\n(val) precision: 0.4542\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4835\n(val) BEST recall: 0.5168\n(val) BEST precision: 0.4542\nmean prediction: 0.06536600757257047\n(test) recall: 0.5135\n(test) precision: 0.4425\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4754\n(test) BEST recall: 0.5135\n(test) BEST precision: 0.4425\n(val) 0.9406 (test) 0.9362\n\nmean prediction: 0.0713450975809279\n(train) recall: 0.7450\n(train) precision: 0.5817\n(train) BEST threshold: 0.4583\n(train) BEST f1: 0.6681\n(train) BEST recall: 0.8289\n(train) BEST precision: 0.5596\n0.9559489956241154\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 91: 100%|██████████| 19/19 [00:03<00:00,  5.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01846414804458618\nAVG PURE EPOCH LOSS: 0.017389776185154915\nLR: 0.0011\nmean prediction: 0.06099912357581069\n(val) recall: 0.5168\n(val) precision: 0.4559\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4845\n(val) BEST recall: 0.5168\n(val) BEST precision: 0.4559\nmean prediction: 0.06562894404711822\n(test) recall: 0.5126\n(test) precision: 0.4399\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4735\n(test) BEST recall: 0.5126\n(test) BEST precision: 0.4399\n(val) 0.9408 (test) 0.9358\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 92: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018449921160936356\nAVG PURE EPOCH LOSS: 0.017374452203512192\nLR: 0.0011\nmean prediction: 0.06053169734151329\n(val) recall: 0.5157\n(val) precision: 0.4585\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4854\n(val) BEST recall: 0.5157\n(val) BEST precision: 0.4585\nmean prediction: 0.06531342027766092\n(test) recall: 0.5107\n(test) precision: 0.4404\n(test) BEST threshold: 0.5417\n(test) BEST f1: 0.4738\n(test) BEST recall: 0.4734\n(test) BEST precision: 0.4743\n(val) 0.9412 (test) 0.9359\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 93: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018397629261016846\nAVG PURE EPOCH LOSS: 0.017321104183793068\nLR: 0.0011\nmean prediction: 0.06257668711656442\n(val) recall: 0.5201\n(val) precision: 0.4472\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4809\n(val) BEST recall: 0.5201\n(val) BEST precision: 0.4472\nmean prediction: 0.06725915018931426\n(test) recall: 0.5219\n(test) precision: 0.4371\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4757\n(test) BEST recall: 0.5219\n(test) BEST precision: 0.4371\n(val) 0.9396 (test) 0.9352\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 94: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.01840633898973465\nAVG PURE EPOCH LOSS: 0.017328718677163124\nLR: 0.0011\nmean prediction: 0.06351153958515922\n(val) recall: 0.5244\n(val) precision: 0.4443\n(val) BEST threshold: 0.5417\n(val) BEST f1: 0.4827\n(val) BEST recall: 0.4853\n(val) BEST precision: 0.4801\nmean prediction: 0.06862641985696256\n(test) recall: 0.5247\n(test) precision: 0.4307\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4731\n(test) BEST recall: 0.5247\n(test) BEST precision: 0.4307\n(val) 0.9391 (test) 0.9342\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 95: 100%|██████████| 19/19 [00:03<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018360700458288193\nAVG PURE EPOCH LOSS: 0.01728203520178795\nLR: 0.0011\nmean prediction: 0.06152497808939527\n(val) recall: 0.5179\n(val) precision: 0.4530\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4833\n(val) BEST recall: 0.5179\n(val) BEST precision: 0.4530\nmean prediction: 0.06573411863693732\n(test) recall: 0.5135\n(test) precision: 0.4400\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4739\n(test) BEST recall: 0.5135\n(test) BEST precision: 0.4400\n(val) 0.9404 (test) 0.9358\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 96: 100%|██████████| 19/19 [00:03<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"AVG EPOCH LOSS: 0.018283382058143616\nAVG PURE EPOCH LOSS: 0.017203722149133682\nLR: 0.0011\nmean prediction: 0.060297984224364595\n(val) recall: 0.5147\n(val) precision: 0.4593\n(val) BEST threshold: 0.5000\n(val) BEST f1: 0.4854\n(val) BEST recall: 0.5147\n(val) BEST precision: 0.4593\nmean prediction: 0.06436684896928901\n(test) recall: 0.5098\n(test) precision: 0.4461\n(test) BEST threshold: 0.5000\n(test) BEST f1: 0.4758\n(test) BEST recall: 0.5098\n(test) BEST precision: 0.4461\n(val) 0.9413 (test) 0.9367\n\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 97:  95%|█████████▍| 18/19 [00:03<00:00,  5.66it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 39\u001b[0m Y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mapply_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# print(Y_train_pred.shape, Y_train[batch_idx].shape)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# print(Y_train_pred.dtype, Y_train[batch_idx].dtype)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Y_train_pred = Y_train_pred.mean(1)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(Y_train_pred, Y_train[batch_idx]\u001b[38;5;241m.\u001b[39mfloat())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[67], line 3\u001b[0m, in \u001b[0;36mapply_model\u001b[0;34m(model, part, idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mautocast(device\u001b[38;5;241m.\u001b[39mtype, enabled\u001b[38;5;241m=\u001b[39mamp_enabled, dtype\u001b[38;5;241m=\u001b[39mamp_dtype)  \u001b[38;5;66;03m# type: ignore[code]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_model\u001b[39m(model, part: \u001b[38;5;28mstr\u001b[39m, idx: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m----> 3\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_cont\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_cat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_cat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# print(pred.shape, pred[..., 0].shape)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/tabm/tabm_reference.py:586\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x_num, x_cat)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m    587\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcolumn_stack([x_\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/tabm/tabm_reference.py:88\u001b[0m, in \u001b[0;36mOneHotEncoding0d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cardinalities)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m---> 88\u001b[0m     [\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;66;03m# NOTE\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;66;03m# This is a quick hack to support out-of-vocabulary categories.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;66;03m# Recall that lib.data.transform_cat encodes categorical features\u001b[39;00m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;66;03m# as follows:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# - In-vocabulary values receive indices from `range(cardinality)`.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;66;03m# - All out-of-vocabulary values (i.e. new categories in validation\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m#   and test data that are not presented in the training data)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m#   receive the index `cardinality`.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# As such, the line below will produce the standard one-hot encoding for\u001b[39;00m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# known categories, and the all-zeros encoding for unknown categories.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# This may not be the best approach to deal with unknown values,\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# but should be enough for our purposes.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m         nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i], cardinality \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, cardinality \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cardinalities)\n\u001b[1;32m    105\u001b[0m     ],\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    107\u001b[0m )\n","File \u001b[0;32m/kaggle/working/tabm/tabm_reference.py:103\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cardinalities)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     88\u001b[0m     [\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;66;03m# NOTE\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;66;03m# This is a quick hack to support out-of-vocabulary categories.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;66;03m# Recall that lib.data.transform_cat encodes categorical features\u001b[39;00m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;66;03m# as follows:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# - In-vocabulary values receive indices from `range(cardinality)`.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;66;03m# - All out-of-vocabulary values (i.e. new categories in validation\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m#   and test data that are not presented in the training data)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m#   receive the index `cardinality`.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# As such, the line below will produce the standard one-hot encoding for\u001b[39;00m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# known categories, and the all-zeros encoding for unknown categories.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# This may not be the best approach to deal with unknown values,\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# but should be enough for our purposes.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcardinality\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, cardinality \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cardinalities)\n\u001b[1;32m    105\u001b[0m     ],\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    107\u001b[0m )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":71},{"cell_type":"code","source":"evaluate('val')","metadata":{"id":"0QkvNIzG7ih9","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:53:05.199671Z","iopub.execute_input":"2024-12-04T00:53:05.199985Z","iopub.status.idle":"2024-12-04T00:53:05.593335Z","shell.execute_reply.started":"2024-12-04T00:53:05.199959Z","shell.execute_reply":"2024-12-04T00:53:05.592522Z"}},"outputs":[{"name":"stdout","text":"mean prediction: 0.08904469763365469\n(val) recall: 0.5429\n(val) precision: 0.3281\n(val) BEST threshold: 0.5833\n(val) BEST f1: 0.4327\n(val) BEST recall: 0.4191\n(val) BEST precision: 0.4473\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"0.9155711364300322"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"a = torch.tensor([\n    [1.0, 0.94, 0.8],\n    [0.1, 0.6, 0.7],\n    [0.23, 0.1, 0.9]\n])\n\nb = torch.tensor([1.0, 0.0, 1.0])\n\nprint(a.flatten(0, 1))\nprint(b.repeat_interleave(3))","metadata":{"id":"4aJonpjfCrDz"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weights_path = '/kaggle/working/sergey_tabm_model.pth'\ntorch.save(model.state_dict(), weights_path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vx7795FDmmXi","outputId":"9bc2955a-1e05-439e-e000-bef0b28783a2","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:24:49.807999Z","iopub.execute_input":"2024-12-04T02:24:49.808373Z","iopub.status.idle":"2024-12-04T02:24:49.823154Z","shell.execute_reply.started":"2024-12-04T02:24:49.808342Z","shell.execute_reply":"2024-12-04T02:24:49.822030Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"model.predict()","metadata":{"id":"P3ykwTok2MIu"},"outputs":[],"execution_count":null}]}