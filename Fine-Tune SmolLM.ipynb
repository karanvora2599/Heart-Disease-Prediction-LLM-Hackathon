{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\ncannot import name 'quantize_' from 'torchao.quantization' (c:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchao\\quantization\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:994\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:59\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     Conv1D,\n\u001b[0;32m     51\u001b[0m     apply_chunking_to_forward,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     prune_linear_layer,\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, HfQuantizer\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_module_from_name\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\quantizers\\__init__.py:14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, AutoQuantizationConfig\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfQuantizer\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\quantizers\\auto.py:44\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizer_quanto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantoHfQuantizer\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizer_torchao\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchAoHfQuantizer\n\u001b[0;32m     47\u001b[0m AUTO_QUANTIZER_MAPPING \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawq\u001b[39m\u001b[38;5;124m\"\u001b[39m: AwqQuantizer,\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m: Bnb4BitHfQuantizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitnet\u001b[39m\u001b[38;5;124m\"\u001b[39m: BitNetHfQuantizer,\n\u001b[0;32m     60\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\quantizers\\quantizer_torchao.py:35\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchao_available():\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantize_\n\u001b[0;32m     37\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'quantize_' from 'torchao.quantization' (c:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchao\\quantization\\__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample, losses\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\losses\\__init__.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mOnlineContrastiveLoss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMegaBatchMarginLoss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderLoss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Triplet losses\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBatchHardTripletLoss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\losses\\DenoisingAutoEncoderLoss.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable, Dict\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, AutoTokenizer, AutoModelForCausalLM, PreTrainedModel\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      8\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\ncannot import name 'quantize_' from 'torchao.quantization' (c:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchao\\quantization\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import InputExample, losses\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path = 'dataset/processed_inputs.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess(df_input, df_outputs):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "    ```\n",
    "    df_input = pd.read_csv('dataset/inputs.csv')\n",
    "    df_outputs = pd.read_csv('dataset/labels.csv')\n",
    "\n",
    "    df = preprocess(df_input, df_outputs)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    df = pd.merge(df_input, df_outputs, on='PatientID', how='inner')\n",
    "\n",
    "    # Which columns to keep\n",
    "    columns_to_keep = [\n",
    "        'PatientID',\n",
    "        'Sex',\n",
    "        'HIVTesting',\n",
    "        'ECigaretteUsage',\n",
    "        'DifficultyConcentrating',\n",
    "        'HadAsthma',\n",
    "        'HadDepressiveDisorder',\n",
    "        'CovidPos',\n",
    "        'FluVaxLast12',\n",
    "        'RaceEthnicityCategory',\n",
    "        'HadDiabetes',\n",
    "        'DifficultyDressingBathing',\n",
    "        'ChestScan',\n",
    "        'HadCOPD',\n",
    "        'BlindOrVisionDifficulty',\n",
    "        'HighRiskLastYear',\n",
    "        'HadAngina',\n",
    "        'PneumoVaxEver',\n",
    "        'HadSkinCancer',\n",
    "        'HadArthritis',\n",
    "        'DeafOrHardOfHearing',\n",
    "        'AlcoholDrinkers',\n",
    "        'HadKidneyDisease',\n",
    "        'TetanusLast10Tdap',\n",
    "        'SmokerStatus',\n",
    "        'HeightInMeters',\n",
    "        'BMI',\n",
    "        'HadHeartAttack'\n",
    "    ]\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # Turn to bool\n",
    "    columns_to_transform = [\n",
    "        'DifficultyConcentrating',\n",
    "        'HadAsthma',\n",
    "        'HadDepressiveDisorder',\n",
    "        'CovidPos',\n",
    "        'FluVaxLast12',\n",
    "        'DifficultyDressingBathing',\n",
    "        'ChestScan',\n",
    "        'HadCOPD',\n",
    "        'BlindOrVisionDifficulty',\n",
    "        'HighRiskLastYear',\n",
    "        'HadAngina',\n",
    "        'PneumoVaxEver',\n",
    "        'HadSkinCancer',\n",
    "        'HadArthritis',\n",
    "        'DeafOrHardOfHearing',\n",
    "        'AlcoholDrinkers',\n",
    "        'HadKidneyDisease',\n",
    "        'HadHeartAttack'\n",
    "    ]\n",
    "    df[columns_to_transform] = df[columns_to_transform].astype(bool)\n",
    "\n",
    "    # Rounding\n",
    "    df['BMI'] = df['BMI'].round(2)\n",
    "    df['HeightInMeters'] = df['HeightInMeters'].round(2)\n",
    "\n",
    "    ### Fix Column Names\n",
    "    new_columns = ['Patient ID', 'Sex', 'HIV Testing', 'E-Cigarette Usage',\n",
    "               'Difficulty Concentrating', 'Had Asthma', 'Had Depressive Disorder',\n",
    "               'Covid Positive', 'Flu Vaccine Last 12 Months', 'Race/Ethnicity Category', 'Had Diabetes',\n",
    "               'Difficulty Dressing/Bathing', 'Chest Scan', 'Had COPD',\n",
    "               'Blind or Vision Difficulty', 'High Risk Last Year', 'Had Angina',\n",
    "               'Pneumonia Vaccine Ever', 'Had Skin Cancer', 'Had Arthritis', 'Deaf or Hard of Hearing',\n",
    "               'Alcohol Drinkers', 'Had Kidney Disease', 'Tetanus Last 10 Years (Tdap)',\n",
    "               'Smoker Status', 'Height in Meters', 'BMI', 'Had Heart Attack']\n",
    "\n",
    "    df.columns = new_columns\n",
    "\n",
    "    return df\n",
    "\n",
    "df_input =  pd.read_csv('dataset/inputs.csv')\n",
    "df_outputs = pd.read_csv('dataset/labels.csv')\n",
    "df = preprocess(df_input, df_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = df[df['Had Heart Attack'] == 0]\n",
    "class_1 = df[df['Had Heart Attack'] == 1]\n",
    "\n",
    "class_0 = class_0.drop(columns=[\"Had Heart Attack\", \"Patient ID\"])\n",
    "class_1 = class_1.drop(columns=[\"Had Heart Attack\", \"Patient ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(size: int):\n",
    "    # Generate features for class 0 and class 1\n",
    "    feature1 = [\", \".join([f\"{col}: {row[col]}\" for col in class_0.columns]) for _, row in class_0.head(size).iterrows()]\n",
    "    feature2 = [\", \".join([f\"{col}: {row[col]}\" for col in class_1.columns]) for _, row in class_1.head(size).iterrows()]\n",
    "\n",
    "    # Combine features and labels\n",
    "    features = feature1 + feature2\n",
    "    labels = [0] * size + [1] * size\n",
    "\n",
    "    # Shuffle features and labels together\n",
    "    combined = list(zip(features, labels))\n",
    "    random.shuffle(combined)\n",
    "    shuffled_features, shuffled_labels = zip(*combined)\n",
    "\n",
    "    # Convert labels to a tensor\n",
    "    labels_tensor = torch.tensor(shuffled_labels, dtype=torch.float32)\n",
    "\n",
    "    return list(shuffled_features), labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
